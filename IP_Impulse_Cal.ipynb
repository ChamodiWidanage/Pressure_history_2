{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "from scipy.integrate import quad\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "ann_arr = load_model('IP_Arrival_time/Arrival_ANN_1')\n",
    "ann_end = load_model('IP_End_time/End_ANN_2')\n",
    "ann_chg = load_model('IP_Change_time/Change_ANN_3')\n",
    "\n",
    "#Section1\n",
    "ann1 = load_model('IP_Section_1_new/Section1_ANN_3')\n",
    "sc1 = pickle.load(open('IP_Section_1_new/Section1_scaler_ANN_3.pkl', 'rb'))\n",
    "#Section2\n",
    "ann2 = load_model('IP_Section_2_new/Section2_new_ANN_5')\n",
    "sc2 = pickle.load(open('IP_Section_2_new/Section2_new_scaler_ANN_5.pkl', 'rb'))\n",
    "#Section3\n",
    "ann3 = load_model('IP_Section_3_new/Section3_new_ANN_1')\n",
    "sc3 = pickle.load(open('IP_Section_3_new/Section3_new_scaler_ANN_1.pkl', 'rb'))\n",
    "#Section4\n",
    "ann4 = load_model('IP_Section_4_new/Section4_new_ANN_1')\n",
    "sc4 = pickle.load(open('IP_Section_4_new/Section4_new_scaler_ANN_1.pkl', 'rb'))\n",
    "#Section5\n",
    "ann5 = load_model('IP_Section_5_new/Section5_new_ANN_1')\n",
    "sc5 = pickle.load(open('IP_Section_5_new/Section5_new_scaler_ANN_1.pkl', 'rb'))\n",
    "#Section6\n",
    "ann6 = load_model('IP_Section_6_new/Section6_new_ANN_1')\n",
    "sc6 = pickle.load(open('IP_Section_6_new/Section6_new_scaler_ANN_1.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T00:35:44.979150100Z",
     "start_time": "2024-12-10T00:35:29.322742Z"
    }
   },
   "id": "5f68c2a13834def5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "charge_mass = 16.2\n",
    "standoff_distance = 5.7\n",
    "start_time = 0\n",
    "#termination_time = 130\n",
    "interval = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T00:36:20.010666900Z",
     "start_time": "2024-12-10T00:36:19.995151100Z"
    }
   },
   "id": "9a27b03f447f9ce1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "arrival [[6.446565]] end [[41.680073]] change [[10.399284]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z5379606\\AppData\\Local\\Temp\\ipykernel_11060\\2167176811.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  t = np.arange(start, end + interval, interval)\n",
      "C:\\Users\\z5379606\\AppData\\Local\\Temp\\ipykernel_11060\\2167176811.py:73: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  t2= np.arange(arrival_time, end_time + interval, interval)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 1s 5ms/step\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "arr = np.array ([[charge_mass,standoff_distance]])\n",
    "\n",
    "arrival_time = ann_arr.predict(arr)\n",
    "end_time = ann_end.predict(arr)\n",
    "change_time = ann_chg.predict(arr)\n",
    "print (\"arrival\", arrival_time,\"end\", end_time, \"change\", change_time)\n",
    "termination_time = end_time +50\n",
    "\n",
    "def stable_state(start, end, interval):    \n",
    "    t = np.arange(start, end + interval, interval)\n",
    "    t = t.reshape(len(t),1)\n",
    "\n",
    "    p = np.repeat(0, len(t)).reshape(len(t),1)\n",
    "    \n",
    "    values = np.concatenate ((t, p), axis = 1)\n",
    "    return values\n",
    "\n",
    "def p_fluctuation(standoff_distance, d_set):\n",
    "    if 1.5 <= standoff_distance <= 3:\n",
    "        d_set[:,0:3] = sc1.transform(d_set[:,0:3])\n",
    "        p_f = ann1.predict(d_set)\n",
    "        section = 1\n",
    "        \n",
    "    elif 3 < standoff_distance <= 7:\n",
    "        d_set[:,0:3] = sc2.transform(d_set[:,0:3])\n",
    "        p_f = ann2.predict(d_set)\n",
    "        section = 2\n",
    "        \n",
    "    elif 7 < standoff_distance <= 13:\n",
    "        d_set[:,0:3] = sc3.transform(d_set[:,0:3])\n",
    "        p_f = ann3.predict(d_set)\n",
    "        section = 3\n",
    "        \n",
    "    elif 13 < standoff_distance <= 19:\n",
    "        d_set[:,0:3] = sc4.transform(d_set[:,0:3])\n",
    "        p_f = ann4.predict(d_set)\n",
    "        section = 4\n",
    "        \n",
    "    elif 19 < standoff_distance <= 25:\n",
    "        d_set[:,0:3] = sc5.transform(d_set[:,0:3])\n",
    "        p_f = ann5.predict(d_set)\n",
    "        section = 5\n",
    "        \n",
    "    elif 25 < standoff_distance <= 30:\n",
    "        d_set[:,0:3] = sc6.transform(d_set[:,0:3])\n",
    "        p_f = ann6.predict(d_set)\n",
    "        section = 6\n",
    "        \n",
    "    else:\n",
    "        print (\"Out of trained range\")\n",
    "    return p_f, section\n",
    "\n",
    "if termination_time < arrival_time:\n",
    "    start = start_time\n",
    "    end = termination_time\n",
    "    values1 = stable_state(start, end, interval)\n",
    "    arrival_time = 0\n",
    "    end_time = 0\n",
    "\n",
    "else:\n",
    "    start = start_time\n",
    "    end = arrival_time\n",
    "    values1 = stable_state(start, end, interval)\n",
    "    \n",
    "    if termination_time < end_time:\n",
    "        end_time = termination_time\n",
    "        \n",
    "    else:\n",
    "        start = end_time\n",
    "        end = termination_time\n",
    "        values3 = stable_state(start, end, interval)\n",
    "\n",
    "t2= np.arange(arrival_time, end_time + interval, interval)\n",
    "t2 = t2.reshape(len(t2),1)\n",
    "\n",
    "if t2[0] < change_time:\n",
    "    ph2 = np.array([[0, 1]])\n",
    "else:\n",
    "    ph2 = np.array([[1, 0]])\n",
    "    \n",
    "positive = np.array([0, 1])\n",
    "negative = np.array([1, 0])\n",
    "\n",
    "for time in t2[1:]:\n",
    "    if time < change_time:\n",
    "        ph2=np.vstack((ph2,positive))\n",
    "    else:\n",
    "        ph2=np.vstack((ph2,negative))\n",
    "        \n",
    "m2 = np.repeat(charge_mass, len(t2)).reshape(len(t2),1)\n",
    "d2 = np.repeat(standoff_distance, len(t2)).reshape(len(t2),1)\n",
    "d_set = np.concatenate ((m2, d2, t2, ph2), axis = 1)\n",
    "\n",
    "p2, section = p_fluctuation(standoff_distance, d_set)\n",
    "p2 = p2.reshape((-1, 1))\n",
    "values2 = np.concatenate ((t2, p2), axis = 1)\n",
    "\n",
    "\n",
    "if 'values2' in globals():\n",
    "    ml_model = np.concatenate((values1, values2), axis=0)\n",
    "    if 'values3' in globals():\n",
    "        ml_model = np.concatenate((ml_model, values3), axis=0)\n",
    "else:\n",
    "    ml_model = values1\n",
    "print (section)\n",
    "\n",
    "X1 = ml_model[:,0]\n",
    "y1_int = ml_model[:,1]\n",
    "y1 = y1_int + 101.25"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T00:36:24.636Z",
     "start_time": "2024-12-10T00:36:22.948349500Z"
    }
   },
   "id": "5bef0a47f5903d4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = f'G:/Chamodi/Machine_Learning/Pressure_history_2/IP_Num&ANN_Comparison/LSDYNA/{charge_mass}kg/{standoff_distance}m.xlsx'\n",
    "lsdyna = pd.read_excel(file_path)\n",
    "#lsdyna = pd.read_csv(file_path, delimiter=\"\\s+\", skiprows = 8, skipfooter = 1, header = None, names = [\"Time\", \"Pressure\"])\n",
    "X2_original = lsdyna['Time']\n",
    "y2_original = lsdyna['Pressure']\n",
    "X2_original=X2_original*1000\n",
    "y2_original=(y2_original/1000)\n",
    "\n",
    "# Find the indices for the two values closest to value1 and value2\n",
    "index1 = (np.abs(X2_original - start_time)).argmin()\n",
    "index2 = (np.abs(X2_original - termination_time)).argmin()\n",
    "\n",
    "# Extract the ranges from X2 and y2 based on the indices\n",
    "X2 = X2_original[index1:index2+1]\n",
    "y2 = y2_original[index1:index2+1]\n",
    "\n",
    "X2 = X2.to_numpy()\n",
    "y2 = y2.to_numpy()\n",
    "\n",
    "y2_int = y2 - 101.25\n",
    "\n",
    "print(\"Numerical length\",len(y2), \"ANN-based length\", len(y1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98ee2e66fbf9fb57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform numerical integration using the trapezoidal rule\n",
    "area_num = np.trapz(y2_int, X2)\n",
    "area_ann = np.trapz(y1_int, X1)\n",
    "print(f\"Integrated Area Under the Curve: {area_num}, {area_ann}\")\n",
    "\n",
    "# Perform cumulative integration using the trapezoidal rule\n",
    "ci_num = np.cumsum(np.gradient(X2) * y2_int)\n",
    "ci_ann = np.cumsum(np.gradient(X1) * y1_int)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# Plot the original data (y vs time) on the primary y-axis\n",
    "ax1.plot(X2, y2, color = 'blue',label = 'Numerical - Overpressure', linewidth=4)\n",
    "ax1.plot(X1, y1, linestyle = 'dashed', color = 'red', label = 'ANN framework - Overpressure', linewidth=3)\n",
    "ax1.set_xlabel('Time (ms)', fontsize = 30)\n",
    "ax1.set_ylabel('Incident Pressue (kPa)', fontsize = 30)\n",
    "ax1.tick_params(axis='both', labelsize = 30)\n",
    "ax1.set_xticks([60,70,80,90,100,110])\n",
    "ax1.set_yticks([96,100,104,108,112])\n",
    "ax1.set_xlim(start_time,termination_time)\n",
    "#ax1.legend(loc='upper center', bbox_to_anchor=(0.4, -0.2), fontsize=30, ncol=1, frameon = False)\n",
    "\n",
    "# Create a secondary y-axis for the cumulative integration\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(X2, ci_num, color='green', linestyle='dotted',label='Numerical - Impulse', linewidth=3)\n",
    "ax2.plot(X1, ci_ann, linestyle='dashdot', label='ANN framework - Impulse', color='orange', linewidth=3)\n",
    "ax2.set_ylabel('Impulse (Pa.s)', fontsize = 30)\n",
    "ax2.set_yticks([-10,0,10,20,30,40])\n",
    "ax2.tick_params(axis='both', labelsize = 30)\n",
    "#ax2.legend(loc='upper center', bbox_to_anchor=(0.3, -0.45), fontsize=30, ncol=1, frameon = False)\n",
    "\n",
    "plt.savefig(f'IP_Num&ANN_Comparison/Images2/Section{section}/{standoff_distance}m{charge_mass}kg_new2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a10cc045e16f6b60"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.446565]] 16.319999471000003\n",
      "Shape of X: (9172,)\n",
      "Shape of y: (9172,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (9172,), (1, 1))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 52\u001B[0m\n\u001B[0;32m     48\u001B[0m     auc_series \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcumsum(np\u001B[38;5;241m.\u001B[39mgradient(time_values) \u001B[38;5;241m*\u001B[39m pressure_values)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m integration_result, auc_series, time_values, pressure_values\n\u001B[1;32m---> 52\u001B[0m ann_auc, ann_auc_series, ann_time, ann_pressure \u001B[38;5;241m=\u001B[39m \u001B[43mauc_cal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX1\u001B[49m\u001B[43m,\u001B[49m\u001B[43my1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_time_overall\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time_overall\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m num_auc, num_auc_series, num_time, num_pressure \u001B[38;5;241m=\u001B[39m auc_cal(X2_original,y2_original, start_time_overall, end_time_overall)\n\u001B[0;32m     55\u001B[0m fig_auc \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mplot(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n",
      "Cell \u001B[1;32mIn[6], line 40\u001B[0m, in \u001B[0;36mauc_cal\u001B[1;34m(X, y, start_time, end_time)\u001B[0m\n\u001B[0;32m     38\u001B[0m dataset \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTime\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     39\u001B[0m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPressure\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m---> 40\u001B[0m filtered_data \u001B[38;5;241m=\u001B[39m dataset[(\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstart_time\u001B[49m) \u001B[38;5;241m&\u001B[39m (dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m end_time)]\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m#print (filtered_data)\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Extract time and pressure values\u001B[39;00m\n\u001B[0;32m     43\u001B[0m time_values \u001B[38;5;241m=\u001B[39m filtered_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTime\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\python3.9\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m     79\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[1;32m---> 81\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\python3.9\\lib\\site-packages\\pandas\\core\\arraylike.py:60\u001B[0m, in \u001B[0;36mOpsMixin.__ge__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__ge__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__ge__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m---> 60\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mge\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\python3.9\\lib\\site-packages\\pandas\\core\\series.py:6096\u001B[0m, in \u001B[0;36mSeries._cmp_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   6093\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   6095\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 6096\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomparison_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(res_values, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\python3.9\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:270\u001B[0m, in \u001B[0;36mcomparison_op\u001B[1;34m(left, right, op)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rvalues, (np\u001B[38;5;241m.\u001B[39mndarray, ABCExtensionArray)):\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001B[39;00m\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001B[39;00m\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001B[39;00m\n\u001B[0;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lvalues) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(rvalues):\n\u001B[1;32m--> 270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    271\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLengths must match to compare\u001B[39m\u001B[38;5;124m\"\u001B[39m, lvalues\u001B[38;5;241m.\u001B[39mshape, rvalues\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    272\u001B[0m         )\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_extension_dispatch(lvalues, rvalues) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m    275\u001B[0m     (\u001B[38;5;28misinstance\u001B[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001B[38;5;129;01mor\u001B[39;00m right \u001B[38;5;129;01mis\u001B[39;00m NaT)\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_object_dtype(lvalues\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    277\u001B[0m ):\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;66;03m# Call the method on lvalues\u001B[39;00m\n\u001B[0;32m    279\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m op(lvalues, rvalues)\n",
      "\u001B[1;31mValueError\u001B[0m: ('Lengths must match to compare', (9172,), (1, 1))"
     ]
    }
   ],
   "source": [
    "file_path = f'G:/Chamodi/Machine_Learning/Pressure_history_2/IP_Num&ANN_Comparison/LSDYNA/{charge_mass}kg/{standoff_distance}m.xlsx'\n",
    "lsdyna = pd.read_excel(file_path)\n",
    "#lsdyna = pd.read_csv(file_path, delimiter=\"\\s+\", skiprows = 8, skipfooter = 1, header = None, names = [\"Time\", \"Pressure\"])\n",
    "X2_original = lsdyna['Time']\n",
    "y2_original = lsdyna['Pressure']\n",
    "X2_original = (X2_original * 1000).to_numpy()\n",
    "y2_original = (y2_original / 1000).to_numpy()\n",
    "\n",
    "def boundary_search(X,y):\n",
    "    start_time = None\n",
    "    end_time_bs = None\n",
    "    start_index = np.argmax(y)\n",
    "    start_time = X[start_index]\n",
    "    zero_index1 = next((i for i, val in enumerate(y[start_index:], start=0) if val <= 101.25), None)\n",
    "    if isinstance (zero_index1, int):\n",
    "       zero_index1 = zero_index1 + start_index\n",
    "       min_index = np.argmin(y[zero_index1:])+zero_index1\n",
    "       zero_index2 = next((i for i, val in enumerate(y[min_index:], start=0) if val >= 101.25), None)\n",
    "       if isinstance (zero_index2, int):\n",
    "           end_index = zero_index2 + min_index\n",
    "           end_time_bs = X[end_index]\n",
    "       else:\n",
    "           end_time_bs = X[-1]\n",
    "    else:\n",
    "        print('zero_index1 error')\n",
    "    return start_time, end_time_bs\n",
    "\n",
    "\n",
    "start_time_num, end_time_num = boundary_search(X2_original,y2_original)\n",
    "start_time_ann = arrival_time\n",
    "end_time_ann = end_time\n",
    "start_time_overall = min(start_time_num, start_time_ann)\n",
    "end_time_overall = min(end_time_num, end_time_ann)\n",
    "print (start_time_overall, end_time_overall)\n",
    "def auc_cal(X,y, start_time, end_time):\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "    dataset = pd.DataFrame(X, columns=['Time'])\n",
    "    dataset['Pressure'] = y\n",
    "    filtered_data = dataset[(dataset['Time'] >= start_time) & (dataset['Time'] <= end_time)]\n",
    "    #print (filtered_data)\n",
    "    # Extract time and pressure values\n",
    "    time_values = filtered_data['Time'].values\n",
    "    pressure_values = filtered_data['Pressure'].values\n",
    "    \n",
    "    # Integrate using the trapezoidal rule\n",
    "    integration_result = np.trapz(pressure_values, time_values)\n",
    "    auc_series = np.cumsum(np.gradient(time_values) * pressure_values)\n",
    "    \n",
    "    return integration_result, auc_series, time_values, pressure_values\n",
    "\n",
    "ann_auc, ann_auc_series, ann_time, ann_pressure = auc_cal(X1,y1, start_time_overall, end_time_overall)\n",
    "num_auc, num_auc_series, num_time, num_pressure = auc_cal(X2_original,y2_original, start_time_overall, end_time_overall)\n",
    "\n",
    "fig_auc = plt.plot(figsize=(6, 6))\n",
    "\n",
    "plt.plot(num_time, num_auc_series, color = 'red',label = 'Numerical', linewidth=4)\n",
    "plt.plot(ann_time, ann_auc_series, color = 'blue',label = 'ANN', linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "fig_auc2 = plt.plot(figsize=(6, 6))\n",
    "\n",
    "plt.plot(num_time, num_pressure, color = 'red',label = 'Numerical', linewidth=4)\n",
    "plt.plot(ann_time, ann_pressure, color = 'blue',label = 'ANN', linewidth=4)\n",
    "plt.show()\n",
    "\n",
    "error = (abs(ann_auc-num_auc)/num_auc)*100\n",
    "print(error)\n",
    "print ('ann_auc=',ann_auc)\n",
    "print ('num_auc=',num_auc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T00:51:28.602531500Z",
     "start_time": "2024-12-10T00:51:27.685984100Z"
    }
   },
   "id": "b5ab387b8d76f9ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Numerical\n",
    "max_index_num = np.argmax(y2)\n",
    "\n",
    "zero_crossing_index = next((i for i, val in enumerate(y2[max_index_num:], start=0) if val <= 101.25), None)\n",
    "\n",
    "if isinstance (zero_crossing_index, int):\n",
    "    zero_crossing_index = zero_crossing_index+max_index_num\n",
    "    change_time_num = X2[zero_crossing_index]\n",
    "    positive_duration_num = change_time_num - X2[max_index_num]\n",
    "    min_index_num = np.argmin(y2[zero_crossing_index:])+zero_crossing_index\n",
    "    negative_peak_pressure_num = y2[min_index_num]\n",
    "    negative_peak_time_num = X2[min_index_num]\n",
    "    \n",
    "    zero_crossing_index2 = next((i for i, val in enumerate(y2[min_index_num:], start=0) if val >= 101.25), None)\n",
    "    \n",
    "    if isinstance((zero_crossing_index2, zero_crossing_index) , int):\n",
    "        zero_crossing_index2 = zero_crossing_index2+min_index_num\n",
    "        end_time_num = X2[zero_crossing_index2]\n",
    "        negative_duration_num = end_time_num - change_time_num\n",
    "    else:\n",
    "        negative_duration_num = max(X2)-change_time_num\n",
    "else:\n",
    "    positive_duration_num = None\n",
    "\n",
    "if 'negative_peak_pressure_num' not in globals():\n",
    "    negative_peak_pressure_num = None\n",
    "if 'negative_peak_time_num' not in globals():\n",
    "    negative_peak_time_num = None\n",
    "\n",
    "positive_peak_pressure_num = y2[max_index_num]\n",
    "positive_peak_time_num = X2[max_index_num]\n",
    "\n",
    "\n",
    "# ANN-based\n",
    "positive_duration_ann = float(change_time - arrival_time)\n",
    "negative_duration_ann = float(end_time - change_time)\n",
    "\n",
    "max_index_ann = np.argmax(y1)\n",
    "\n",
    "a_zero_crossing_index = next((i for i, val in enumerate(y1[max_index_ann:], start=0) if val <= 101.25), None)\n",
    "\n",
    "if isinstance (a_zero_crossing_index, int):\n",
    "    a_zero_crossing_index = a_zero_crossing_index+max_index_ann\n",
    "    min_index_ann = np.argmin(y1[a_zero_crossing_index:])+a_zero_crossing_index\n",
    "    negative_peak_pressure_ann = y1[min_index_ann]\n",
    "    negative_peak_time_ann = X1[min_index_ann]\n",
    "\n",
    "if 'negative_peak_pressure_ann' not in globals():\n",
    "    negative_peak_pressure_ann = None\n",
    "if 'negative_peak_time_ann' not in globals():\n",
    "    negative_peak_time_ann = None\n",
    "\n",
    "positive_peak_pressure_ann = y1[max_index_ann]\n",
    "positive_peak_time_ann = X1[max_index_ann]\n",
    "\n",
    "def per_diff(value1, value2):\n",
    "    per_dif = (abs(value1-value2)/value1)*100\n",
    "    return per_dif\n",
    "\n",
    "print('positive peak pressure- n', positive_peak_pressure_num, 'a', positive_peak_pressure_ann,'%', per_diff(positive_peak_pressure_num,positive_peak_pressure_ann))\n",
    "print('negative peak pressure- n', negative_peak_pressure_num, 'a', negative_peak_pressure_ann,'%', per_diff(negative_peak_pressure_num,negative_peak_pressure_ann))\n",
    "print('positive peak time- n', positive_peak_time_num, 'a', positive_peak_time_ann, '%', per_diff(positive_peak_time_num, positive_peak_time_ann))\n",
    "print('negative peak time-n', negative_peak_time_num, 'a', negative_peak_time_ann, '%', per_diff(negative_peak_time_num, negative_peak_time_ann))\n",
    "print('positive duration-n', positive_duration_num, 'a', positive_duration_ann, '%', per_diff(positive_duration_num, positive_duration_ann))\n",
    "print('negative duration-n', negative_duration_num, 'a', negative_duration_ann, '%', per_diff(negative_duration_num, negative_duration_ann))\n",
    "print('peak impulse-n', max(ci_num), 'a', max(ci_ann), '%', per_diff(max(ci_num), max(ci_ann)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f316355e53b6b57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
