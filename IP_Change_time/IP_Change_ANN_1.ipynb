{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1 - Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxChR1Rk-umf",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:05.589962600Z",
     "start_time": "2024-08-22T13:34:59.265528800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9CV13Co_HHM",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:06.461971500Z",
     "start_time": "2024-08-22T13:35:05.594961900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 576 entries, 0 to 575\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Charge_mass        576 non-null    float64\n",
      " 1   Standoff_distance  576 non-null    int64  \n",
      " 2   Change_time        576 non-null    float64\n",
      " 3   Change_index       576 non-null    int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 18.1 KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('Change_time.xlsx')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:06.517972700Z",
     "start_time": "2024-08-22T13:35:06.464970800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 2) (576,)\n"
     ]
    }
   ],
   "source": [
    "y = dataset['Change_time']*1000\n",
    "X = dataset.drop(['Change_time','Change_index'], axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:06.614974400Z",
     "start_time": "2024-08-22T13:35:06.478972800Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:07.519986Z",
     "start_time": "2024-08-22T13:35:06.624977500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5edeb2r_agx",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:07.536987100Z",
     "start_time": "2024-08-22T13:35:07.520989300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test,\n",
    "                                                y_test,\n",
    "                                                test_size = 0.5,\n",
    "                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mSLlAT9_eyI"
   },
   "source": [
    "# Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6Hd97Ls__Nz",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:07.834991Z",
     "start_time": "2024-08-22T13:35:07.535987400Z"
    }
   },
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksO_Vv40AHix",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:08.000995900Z",
     "start_time": "2024-08-22T13:35:07.837995300Z"
    }
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=20,\n",
    "                              input_shape=(X_train.shape[1],),\n",
    "                              activation='leaky_relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=15,\n",
    "                              activation='leaky_relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=10,\n",
    "                              activation='leaky_relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFATpzsUAkLL",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:08.103992900Z",
     "start_time": "2024-08-22T13:35:08.002000500Z"
    }
   },
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1,\n",
    "                              activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:08.309997200Z",
     "start_time": "2024-08-22T13:35:08.103992900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 546\n",
      "Trainable params: 546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fq7e4fF6A1yy"
   },
   "source": [
    "# Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pesgbWlCAtB4",
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:08.405004400Z",
     "start_time": "2024-08-22T13:35:08.254999400Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.001)\n",
    "ann.compile(optimizer = opt,\n",
    "            loss = 'mean_squared_error',\n",
    "            metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T13:35:08.492999800Z",
     "start_time": "2024-08-22T13:35:08.380010200Z"
    }
   },
   "outputs": [],
   "source": [
    "# protects from unnecessary further training of the model if a particular metric does not continue to improve over a number of n epochs. In such a case, the model training would be automatically aborted.\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   mode='min',\n",
    "                   patience=50,\n",
    "                   restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c_vV-tiiA5zn",
    "outputId": "4a2b6ee6-ed75-4698-9069-b250e613803f",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-22T13:35:08.495999900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - 1s 28ms/step - loss: 2036.0540 - mae: 37.6306 - val_loss: 2251.6162 - val_mae: 40.0224\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1666.3643 - mae: 33.4279 - val_loss: 1793.6113 - val_mae: 35.3747\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1282.0569 - mae: 28.9220 - val_loss: 1335.3844 - val_mae: 30.4093\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 923.7179 - mae: 24.3812 - val_loss: 902.4295 - val_mae: 25.0561\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 612.8365 - mae: 19.9350 - val_loss: 567.3365 - val_mae: 19.7435\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 407.0117 - mae: 16.5410 - val_loss: 362.2689 - val_mae: 15.4846\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 300.9852 - mae: 14.4294 - val_loss: 269.4070 - val_mae: 13.3793\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 240.6937 - mae: 12.9541 - val_loss: 209.8553 - val_mae: 11.8433\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 185.5268 - mae: 11.4144 - val_loss: 153.8636 - val_mae: 10.1652\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 131.0982 - mae: 9.5907 - val_loss: 104.0319 - val_mae: 8.4420\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 82.1680 - mae: 7.6590 - val_loss: 60.4076 - val_mae: 6.4993\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 44.4591 - mae: 5.6904 - val_loss: 29.6064 - val_mae: 4.5755\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.3960 - mae: 3.8471 - val_loss: 12.7803 - val_mae: 2.9974\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 9.0338 - mae: 2.5853 - val_loss: 7.0974 - val_mae: 2.2739\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 5.3217 - mae: 1.9573 - val_loss: 5.4354 - val_mae: 1.9161\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 4.4627 - mae: 1.7672 - val_loss: 4.9633 - val_mae: 1.7962\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 4.1461 - mae: 1.6946 - val_loss: 4.6418 - val_mae: 1.7218\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 3.9080 - mae: 1.6303 - val_loss: 4.3847 - val_mae: 1.6590\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 3.6996 - mae: 1.5961 - val_loss: 4.0028 - val_mae: 1.6054\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 3.4990 - mae: 1.5490 - val_loss: 3.8646 - val_mae: 1.5521\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.2817 - mae: 1.4956 - val_loss: 3.5475 - val_mae: 1.5107\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 3.1335 - mae: 1.4608 - val_loss: 3.3755 - val_mae: 1.4692\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.9999 - mae: 1.4295 - val_loss: 3.2336 - val_mae: 1.4343\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.8764 - mae: 1.3971 - val_loss: 3.0310 - val_mae: 1.3926\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.7627 - mae: 1.3685 - val_loss: 2.9188 - val_mae: 1.3672\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.6686 - mae: 1.3442 - val_loss: 2.7561 - val_mae: 1.3386\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.5769 - mae: 1.3206 - val_loss: 2.6946 - val_mae: 1.3250\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 2.5091 - mae: 1.3051 - val_loss: 2.6374 - val_mae: 1.3102\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 2.4315 - mae: 1.2774 - val_loss: 2.4565 - val_mae: 1.2685\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 2.3661 - mae: 1.2626 - val_loss: 2.4354 - val_mae: 1.2643\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.3504 - mae: 1.2659 - val_loss: 2.3807 - val_mae: 1.2520\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.2979 - mae: 1.2374 - val_loss: 2.2287 - val_mae: 1.2138\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.2212 - mae: 1.2285 - val_loss: 2.2987 - val_mae: 1.2362\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.2116 - mae: 1.2228 - val_loss: 2.1509 - val_mae: 1.1947\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 2.1288 - mae: 1.2071 - val_loss: 2.1757 - val_mae: 1.2042\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0846 - mae: 1.1908 - val_loss: 2.0565 - val_mae: 1.1641\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 2.0442 - mae: 1.1749 - val_loss: 2.0395 - val_mae: 1.1630\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0094 - mae: 1.1714 - val_loss: 1.9998 - val_mae: 1.1520\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 1.9801 - mae: 1.1567 - val_loss: 1.9452 - val_mae: 1.1329\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 1.9375 - mae: 1.1468 - val_loss: 1.9245 - val_mae: 1.1278\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.9049 - mae: 1.1414 - val_loss: 1.8900 - val_mae: 1.1174\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 1.8720 - mae: 1.1273 - val_loss: 1.8294 - val_mae: 1.0967\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 1.8405 - mae: 1.1184 - val_loss: 1.8036 - val_mae: 1.0886\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.8089 - mae: 1.1128 - val_loss: 1.7811 - val_mae: 1.0825\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7740 - mae: 1.0981 - val_loss: 1.7430 - val_mae: 1.0685\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.7755 - mae: 1.0867 - val_loss: 1.7167 - val_mae: 1.0597\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 1.7248 - mae: 1.0873 - val_loss: 1.6864 - val_mae: 1.0516\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 1.6880 - mae: 1.0732 - val_loss: 1.6442 - val_mae: 1.0402\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 1.6585 - mae: 1.0525 - val_loss: 1.6323 - val_mae: 1.0357\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.6189 - mae: 1.0528 - val_loss: 1.6190 - val_mae: 1.0344\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.5895 - mae: 1.0397 - val_loss: 1.5569 - val_mae: 1.0067\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.5639 - mae: 1.0300 - val_loss: 1.5724 - val_mae: 1.0196\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 2s 130ms/step - loss: 1.5341 - mae: 1.0238 - val_loss: 1.5205 - val_mae: 0.9982\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 1.5038 - mae: 1.0099 - val_loss: 1.4806 - val_mae: 0.9817\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.4792 - mae: 1.0066 - val_loss: 1.4667 - val_mae: 0.9809\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4434 - mae: 0.9900 - val_loss: 1.4325 - val_mae: 0.9665\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.4165 - mae: 0.9790 - val_loss: 1.4020 - val_mae: 0.9558\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.3905 - mae: 0.9709 - val_loss: 1.3812 - val_mae: 0.9489\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.3673 - mae: 0.9665 - val_loss: 1.3613 - val_mae: 0.9456\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.3439 - mae: 0.9498 - val_loss: 1.3585 - val_mae: 0.9473\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.3162 - mae: 0.9494 - val_loss: 1.3164 - val_mae: 0.9308\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.2885 - mae: 0.9338 - val_loss: 1.2796 - val_mae: 0.9144\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 1.2606 - mae: 0.9201 - val_loss: 1.2671 - val_mae: 0.9137\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.2440 - mae: 0.9227 - val_loss: 1.2072 - val_mae: 0.8862\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.2165 - mae: 0.8977 - val_loss: 1.2298 - val_mae: 0.9014\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 1.1906 - mae: 0.9001 - val_loss: 1.1860 - val_mae: 0.8810\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 1.1598 - mae: 0.8859 - val_loss: 1.1570 - val_mae: 0.8679\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.1430 - mae: 0.8788 - val_loss: 1.1463 - val_mae: 0.8668\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.1223 - mae: 0.8629 - val_loss: 1.1174 - val_mae: 0.8563\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.1168 - mae: 0.8733 - val_loss: 1.0682 - val_mae: 0.8290\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.0860 - mae: 0.8460 - val_loss: 1.0932 - val_mae: 0.8498\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.0561 - mae: 0.8454 - val_loss: 1.0304 - val_mae: 0.8176\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 1.0309 - mae: 0.8298 - val_loss: 1.0400 - val_mae: 0.8253\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 1.0028 - mae: 0.8209 - val_loss: 0.9988 - val_mae: 0.8067\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.9892 - mae: 0.8104 - val_loss: 0.9986 - val_mae: 0.8074\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 3s 183ms/step - loss: 0.9641 - mae: 0.8032 - val_loss: 0.9763 - val_mae: 0.7990\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.9524 - mae: 0.8015 - val_loss: 0.9266 - val_mae: 0.7743\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.9225 - mae: 0.7808 - val_loss: 0.9596 - val_mae: 0.7944\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 2s 182ms/step - loss: 0.9086 - mae: 0.7806 - val_loss: 0.9085 - val_mae: 0.7670\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.8810 - mae: 0.7630 - val_loss: 0.8824 - val_mae: 0.7577\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 2s 124ms/step - loss: 0.8650 - mae: 0.7571 - val_loss: 0.8790 - val_mae: 0.7586\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.8493 - mae: 0.7575 - val_loss: 0.8318 - val_mae: 0.7327\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.8375 - mae: 0.7390 - val_loss: 0.8740 - val_mae: 0.7607\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.8101 - mae: 0.7378 - val_loss: 0.8126 - val_mae: 0.7278\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7863 - mae: 0.7205 - val_loss: 0.7871 - val_mae: 0.7146\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7698 - mae: 0.7142 - val_loss: 0.7816 - val_mae: 0.7127\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7560 - mae: 0.7058 - val_loss: 0.7577 - val_mae: 0.7029\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.7363 - mae: 0.7017 - val_loss: 0.7406 - val_mae: 0.6934\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.7166 - mae: 0.6890 - val_loss: 0.7323 - val_mae: 0.6892\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 3s 177ms/step - loss: 0.7005 - mae: 0.6843 - val_loss: 0.6974 - val_mae: 0.6723\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6873 - mae: 0.6685 - val_loss: 0.7150 - val_mae: 0.6831\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6772 - mae: 0.6707 - val_loss: 0.6987 - val_mae: 0.6756\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.6577 - mae: 0.6634 - val_loss: 0.6536 - val_mae: 0.6504\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.6384 - mae: 0.6488 - val_loss: 0.6487 - val_mae: 0.6475\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.6231 - mae: 0.6405 - val_loss: 0.6287 - val_mae: 0.6394\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.6145 - mae: 0.6404 - val_loss: 0.6075 - val_mae: 0.6267\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.5989 - mae: 0.6303 - val_loss: 0.6260 - val_mae: 0.6369\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.5841 - mae: 0.6204 - val_loss: 0.5943 - val_mae: 0.6212\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.5707 - mae: 0.6162 - val_loss: 0.5758 - val_mae: 0.6103\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 0.5561 - mae: 0.6089 - val_loss: 0.5629 - val_mae: 0.6028\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.5511 - mae: 0.6006 - val_loss: 0.5906 - val_mae: 0.6176\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.5386 - mae: 0.6001 - val_loss: 0.5287 - val_mae: 0.5823\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.5202 - mae: 0.5853 - val_loss: 0.5473 - val_mae: 0.5942\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.5037 - mae: 0.5779 - val_loss: 0.5118 - val_mae: 0.5754\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.4918 - mae: 0.5708 - val_loss: 0.5200 - val_mae: 0.5787\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.4802 - mae: 0.5649 - val_loss: 0.4909 - val_mae: 0.5638\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.4696 - mae: 0.5586 - val_loss: 0.4798 - val_mae: 0.5574\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4599 - mae: 0.5530 - val_loss: 0.4905 - val_mae: 0.5621\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.4469 - mae: 0.5459 - val_loss: 0.4545 - val_mae: 0.5430\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.4386 - mae: 0.5386 - val_loss: 0.4590 - val_mae: 0.5450\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.4261 - mae: 0.5287 - val_loss: 0.4447 - val_mae: 0.5368\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 0.4190 - mae: 0.5302 - val_loss: 0.4212 - val_mae: 0.5228\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.4152 - mae: 0.5197 - val_loss: 0.4329 - val_mae: 0.5287\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.3996 - mae: 0.5118 - val_loss: 0.4204 - val_mae: 0.5216\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.3911 - mae: 0.5101 - val_loss: 0.3951 - val_mae: 0.5079\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.3830 - mae: 0.5029 - val_loss: 0.3839 - val_mae: 0.5011\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 1s 102ms/step - loss: 0.3820 - mae: 0.5025 - val_loss: 0.3888 - val_mae: 0.5030\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.3720 - mae: 0.4952 - val_loss: 0.3829 - val_mae: 0.4987\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.3581 - mae: 0.4866 - val_loss: 0.3779 - val_mae: 0.4950\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 2s 125ms/step - loss: 0.3466 - mae: 0.4815 - val_loss: 0.3527 - val_mae: 0.4816\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.3416 - mae: 0.4752 - val_loss: 0.3409 - val_mae: 0.4735\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.3339 - mae: 0.4699 - val_loss: 0.3501 - val_mae: 0.4762\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3224 - mae: 0.4607 - val_loss: 0.3299 - val_mae: 0.4656\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3155 - mae: 0.4566 - val_loss: 0.3206 - val_mae: 0.4595\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.3103 - mae: 0.4513 - val_loss: 0.3095 - val_mae: 0.4518\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3055 - mae: 0.4464 - val_loss: 0.3023 - val_mae: 0.4469\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2979 - mae: 0.4397 - val_loss: 0.3264 - val_mae: 0.4554\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2908 - mae: 0.4366 - val_loss: 0.2883 - val_mae: 0.4358\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2852 - mae: 0.4292 - val_loss: 0.3102 - val_mae: 0.4436\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2821 - mae: 0.4276 - val_loss: 0.2805 - val_mae: 0.4291\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2743 - mae: 0.4208 - val_loss: 0.2693 - val_mae: 0.4212\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2694 - mae: 0.4206 - val_loss: 0.2942 - val_mae: 0.4298\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2607 - mae: 0.4130 - val_loss: 0.2568 - val_mae: 0.4136\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2597 - mae: 0.4104 - val_loss: 0.2640 - val_mae: 0.4133\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2523 - mae: 0.4025 - val_loss: 0.2662 - val_mae: 0.4120\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2473 - mae: 0.3982 - val_loss: 0.2449 - val_mae: 0.4042\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2596 - mae: 0.4102 - val_loss: 0.2602 - val_mae: 0.4056\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2395 - mae: 0.3906 - val_loss: 0.2341 - val_mae: 0.3931\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2361 - mae: 0.3901 - val_loss: 0.2259 - val_mae: 0.3874\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.2302 - mae: 0.3858 - val_loss: 0.2230 - val_mae: 0.3832\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2269 - mae: 0.3834 - val_loss: 0.2240 - val_mae: 0.3815\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2243 - mae: 0.3833 - val_loss: 0.2099 - val_mae: 0.3775\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2210 - mae: 0.3785 - val_loss: 0.2148 - val_mae: 0.3725\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2178 - mae: 0.3748 - val_loss: 0.2103 - val_mae: 0.3686\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2148 - mae: 0.3741 - val_loss: 0.2135 - val_mae: 0.3678\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2109 - mae: 0.3693 - val_loss: 0.2146 - val_mae: 0.3660\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2071 - mae: 0.3656 - val_loss: 0.1929 - val_mae: 0.3615\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2033 - mae: 0.3629 - val_loss: 0.1972 - val_mae: 0.3536\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1961 - mae: 0.3568 - val_loss: 0.1808 - val_mae: 0.3452\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1960 - mae: 0.3513 - val_loss: 0.1912 - val_mae: 0.3464\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1953 - mae: 0.3552 - val_loss: 0.1880 - val_mae: 0.3442\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2005 - mae: 0.3579 - val_loss: 0.1705 - val_mae: 0.3380\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1883 - mae: 0.3461 - val_loss: 0.1704 - val_mae: 0.3330\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1842 - mae: 0.3453 - val_loss: 0.1668 - val_mae: 0.3306\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.1848 - mae: 0.3442 - val_loss: 0.1727 - val_mae: 0.3286\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1858 - mae: 0.3452 - val_loss: 0.1603 - val_mae: 0.3311\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1784 - mae: 0.3380 - val_loss: 0.1712 - val_mae: 0.3246\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1770 - mae: 0.3352 - val_loss: 0.1581 - val_mae: 0.3194\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1759 - mae: 0.3362 - val_loss: 0.1591 - val_mae: 0.3181\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.1723 - mae: 0.3318 - val_loss: 0.1518 - val_mae: 0.3143\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 0.1700 - mae: 0.3311 - val_loss: 0.1529 - val_mae: 0.3131\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1670 - mae: 0.3264 - val_loss: 0.1421 - val_mae: 0.3085\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1678 - mae: 0.3285 - val_loss: 0.1481 - val_mae: 0.3080\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1661 - mae: 0.3252 - val_loss: 0.1441 - val_mae: 0.3051\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1678 - mae: 0.3294 - val_loss: 0.1546 - val_mae: 0.3075\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1687 - mae: 0.3273 - val_loss: 0.1465 - val_mae: 0.3015\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1626 - mae: 0.3204 - val_loss: 0.1390 - val_mae: 0.2988\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.1609 - mae: 0.3191 - val_loss: 0.1334 - val_mae: 0.2960\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.1604 - mae: 0.3210 - val_loss: 0.1280 - val_mae: 0.2944\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.1567 - mae: 0.3122 - val_loss: 0.1249 - val_mae: 0.2922\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.1541 - mae: 0.3117 - val_loss: 0.1279 - val_mae: 0.2905\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.1556 - mae: 0.3160 - val_loss: 0.1269 - val_mae: 0.2892\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1535 - mae: 0.3100 - val_loss: 0.1212 - val_mae: 0.2875\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1553 - mae: 0.3149 - val_loss: 0.1217 - val_mae: 0.2869\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1531 - mae: 0.3097 - val_loss: 0.1178 - val_mae: 0.2876\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.1492 - mae: 0.3070 - val_loss: 0.1223 - val_mae: 0.2820\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1499 - mae: 0.3098 - val_loss: 0.1211 - val_mae: 0.2797\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.1512 - mae: 0.3072 - val_loss: 0.1298 - val_mae: 0.2809\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.1511 - mae: 0.3052 - val_loss: 0.1178 - val_mae: 0.2776\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1486 - mae: 0.3028 - val_loss: 0.1126 - val_mae: 0.2772\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1480 - mae: 0.3038 - val_loss: 0.1103 - val_mae: 0.2783\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.1445 - mae: 0.2994 - val_loss: 0.1141 - val_mae: 0.2722\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.1465 - mae: 0.3006 - val_loss: 0.1169 - val_mae: 0.2719\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.1455 - mae: 0.3033 - val_loss: 0.1089 - val_mae: 0.2710\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.1493 - mae: 0.3069 - val_loss: 0.1087 - val_mae: 0.2691\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.1446 - mae: 0.2969 - val_loss: 0.1068 - val_mae: 0.2683\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.1443 - mae: 0.2947 - val_loss: 0.1027 - val_mae: 0.2660\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.1417 - mae: 0.2945 - val_loss: 0.1030 - val_mae: 0.2690\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.1412 - mae: 0.2955 - val_loss: 0.1115 - val_mae: 0.2662\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.1384 - mae: 0.2884 - val_loss: 0.1051 - val_mae: 0.2735\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.1425 - mae: 0.2930 - val_loss: 0.1000 - val_mae: 0.2654\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.1418 - mae: 0.2943 - val_loss: 0.1004 - val_mae: 0.2672\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.1398 - mae: 0.2929 - val_loss: 0.1023 - val_mae: 0.2612\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.1406 - mae: 0.2898 - val_loss: 0.0992 - val_mae: 0.2604\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.1423 - mae: 0.2938 - val_loss: 0.1215 - val_mae: 0.2680\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.1387 - mae: 0.2898 - val_loss: 0.1010 - val_mae: 0.2582\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.1415 - mae: 0.2909 - val_loss: 0.0953 - val_mae: 0.2564\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.1383 - mae: 0.2870 - val_loss: 0.0956 - val_mae: 0.2597\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1357 - mae: 0.2857 - val_loss: 0.0960 - val_mae: 0.2618\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.1403 - mae: 0.2893 - val_loss: 0.0932 - val_mae: 0.2535\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1350 - mae: 0.2837 - val_loss: 0.1118 - val_mae: 0.2605\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1369 - mae: 0.2889 - val_loss: 0.0923 - val_mae: 0.2532\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.1345 - mae: 0.2801 - val_loss: 0.0917 - val_mae: 0.2517\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.1340 - mae: 0.2814 - val_loss: 0.1009 - val_mae: 0.2536\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.1411 - mae: 0.2915 - val_loss: 0.1029 - val_mae: 0.2555\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.1361 - mae: 0.2882 - val_loss: 0.1062 - val_mae: 0.2572\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.1414 - mae: 0.2893 - val_loss: 0.1002 - val_mae: 0.2520\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.1439 - mae: 0.2947 - val_loss: 0.0986 - val_mae: 0.2518\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1473 - mae: 0.2977 - val_loss: 0.1058 - val_mae: 0.2541\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1345 - mae: 0.2818 - val_loss: 0.0917 - val_mae: 0.2472\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.1313 - mae: 0.2779 - val_loss: 0.0886 - val_mae: 0.2507\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1314 - mae: 0.2798 - val_loss: 0.0919 - val_mae: 0.2543\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1315 - mae: 0.2782 - val_loss: 0.0873 - val_mae: 0.2457\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.1293 - mae: 0.2749 - val_loss: 0.0905 - val_mae: 0.2546\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.1305 - mae: 0.2747 - val_loss: 0.0871 - val_mae: 0.2439\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 3s 217ms/step - loss: 0.1303 - mae: 0.2737 - val_loss: 0.0858 - val_mae: 0.2450\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 2s 183ms/step - loss: 0.1298 - mae: 0.2770 - val_loss: 0.0864 - val_mae: 0.2427\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.1310 - mae: 0.2743 - val_loss: 0.0966 - val_mae: 0.2462\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.1350 - mae: 0.2795 - val_loss: 0.0926 - val_mae: 0.2440\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.1281 - mae: 0.2731 - val_loss: 0.0896 - val_mae: 0.2431\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.1309 - mae: 0.2749 - val_loss: 0.0868 - val_mae: 0.2436\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.1275 - mae: 0.2717 - val_loss: 0.0848 - val_mae: 0.2414\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.1289 - mae: 0.2712 - val_loss: 0.0846 - val_mae: 0.2401\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1265 - mae: 0.2732 - val_loss: 0.0860 - val_mae: 0.2400\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1283 - mae: 0.2738 - val_loss: 0.0886 - val_mae: 0.2407\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.1285 - mae: 0.2719 - val_loss: 0.1037 - val_mae: 0.2477\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1306 - mae: 0.2748 - val_loss: 0.0833 - val_mae: 0.2389\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.1307 - mae: 0.2752 - val_loss: 0.0875 - val_mae: 0.2394\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.1288 - mae: 0.2733 - val_loss: 0.0937 - val_mae: 0.2422\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 1s 98ms/step - loss: 0.1285 - mae: 0.2710 - val_loss: 0.0842 - val_mae: 0.2363\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.1255 - mae: 0.2673 - val_loss: 0.0841 - val_mae: 0.2361\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.1267 - mae: 0.2693 - val_loss: 0.0833 - val_mae: 0.2370\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.1258 - mae: 0.2649 - val_loss: 0.0806 - val_mae: 0.2364\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.1251 - mae: 0.2693 - val_loss: 0.0812 - val_mae: 0.2352\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.1277 - mae: 0.2692 - val_loss: 0.0798 - val_mae: 0.2383\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.1280 - mae: 0.2711 - val_loss: 0.0820 - val_mae: 0.2381\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 1s 95ms/step - loss: 0.1233 - mae: 0.2676 - val_loss: 0.0900 - val_mae: 0.2387\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.1254 - mae: 0.2669 - val_loss: 0.0859 - val_mae: 0.2485\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 2s 124ms/step - loss: 0.1248 - mae: 0.2705 - val_loss: 0.0809 - val_mae: 0.2340\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1270 - mae: 0.2701 - val_loss: 0.0809 - val_mae: 0.2327\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.1228 - mae: 0.2641 - val_loss: 0.0832 - val_mae: 0.2421\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1224 - mae: 0.2657 - val_loss: 0.0801 - val_mae: 0.2400\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.1222 - mae: 0.2635 - val_loss: 0.0777 - val_mae: 0.2307\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.1206 - mae: 0.2604 - val_loss: 0.0785 - val_mae: 0.2345\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.1222 - mae: 0.2644 - val_loss: 0.0786 - val_mae: 0.2308\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1192 - mae: 0.2567 - val_loss: 0.0845 - val_mae: 0.2468\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.1216 - mae: 0.2648 - val_loss: 0.0773 - val_mae: 0.2316\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1205 - mae: 0.2612 - val_loss: 0.0802 - val_mae: 0.2393\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1205 - mae: 0.2619 - val_loss: 0.0805 - val_mae: 0.2315\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.1230 - mae: 0.2657 - val_loss: 0.0758 - val_mae: 0.2294\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1221 - mae: 0.2642 - val_loss: 0.0865 - val_mae: 0.2330\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1238 - mae: 0.2659 - val_loss: 0.0791 - val_mae: 0.2302\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1240 - mae: 0.2674 - val_loss: 0.0872 - val_mae: 0.2517\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1255 - mae: 0.2712 - val_loss: 0.0771 - val_mae: 0.2319\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1194 - mae: 0.2617 - val_loss: 0.0763 - val_mae: 0.2300\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1198 - mae: 0.2607 - val_loss: 0.0743 - val_mae: 0.2283\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1185 - mae: 0.2585 - val_loss: 0.0767 - val_mae: 0.2302\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1188 - mae: 0.2592 - val_loss: 0.0757 - val_mae: 0.2295\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1184 - mae: 0.2605 - val_loss: 0.0771 - val_mae: 0.2318\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1178 - mae: 0.2568 - val_loss: 0.0855 - val_mae: 0.2495\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.1212 - mae: 0.2634 - val_loss: 0.0815 - val_mae: 0.2415\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1177 - mae: 0.2583 - val_loss: 0.0744 - val_mae: 0.2275\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1179 - mae: 0.2582 - val_loss: 0.0752 - val_mae: 0.2267\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1189 - mae: 0.2605 - val_loss: 0.0817 - val_mae: 0.2427\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.1176 - mae: 0.2586 - val_loss: 0.0773 - val_mae: 0.2344\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1164 - mae: 0.2556 - val_loss: 0.0747 - val_mae: 0.2310\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1170 - mae: 0.2560 - val_loss: 0.0863 - val_mae: 0.2485\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1193 - mae: 0.2605 - val_loss: 0.0757 - val_mae: 0.2326\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.1184 - mae: 0.2630 - val_loss: 0.0730 - val_mae: 0.2259\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.1183 - mae: 0.2588 - val_loss: 0.0780 - val_mae: 0.2224\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.1170 - mae: 0.2571 - val_loss: 0.0836 - val_mae: 0.2475\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.1167 - mae: 0.2564 - val_loss: 0.0740 - val_mae: 0.2252\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.1147 - mae: 0.2549 - val_loss: 0.0746 - val_mae: 0.2218\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.1153 - mae: 0.2556 - val_loss: 0.0829 - val_mae: 0.2273\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.1238 - mae: 0.2626 - val_loss: 0.0751 - val_mae: 0.2228\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.1258 - mae: 0.2690 - val_loss: 0.0821 - val_mae: 0.2431\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.1151 - mae: 0.2531 - val_loss: 0.0760 - val_mae: 0.2326\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1164 - mae: 0.2571 - val_loss: 0.0737 - val_mae: 0.2260\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1225 - mae: 0.2595 - val_loss: 0.0868 - val_mae: 0.2292\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 0.1147 - mae: 0.2543 - val_loss: 0.0731 - val_mae: 0.2194\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1142 - mae: 0.2553 - val_loss: 0.0736 - val_mae: 0.2281\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.1131 - mae: 0.2507 - val_loss: 0.0749 - val_mae: 0.2228\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1133 - mae: 0.2523 - val_loss: 0.0703 - val_mae: 0.2212\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.1103 - mae: 0.2471 - val_loss: 0.0884 - val_mae: 0.2297\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.1151 - mae: 0.2532 - val_loss: 0.0715 - val_mae: 0.2242\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1096 - mae: 0.2473 - val_loss: 0.0705 - val_mae: 0.2200\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1150 - mae: 0.2547 - val_loss: 0.0765 - val_mae: 0.2198\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.1182 - mae: 0.2580 - val_loss: 0.0758 - val_mae: 0.2330\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.1167 - mae: 0.2617 - val_loss: 0.0771 - val_mae: 0.2370\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.1106 - mae: 0.2495 - val_loss: 0.0741 - val_mae: 0.2196\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.1088 - mae: 0.2462 - val_loss: 0.0721 - val_mae: 0.2176\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.1079 - mae: 0.2450 - val_loss: 0.0699 - val_mae: 0.2177\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.1105 - mae: 0.2480 - val_loss: 0.0696 - val_mae: 0.2200\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.1104 - mae: 0.2490 - val_loss: 0.0698 - val_mae: 0.2225\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 1s 99ms/step - loss: 0.1114 - mae: 0.2541 - val_loss: 0.0789 - val_mae: 0.2368\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.1123 - mae: 0.2548 - val_loss: 0.0790 - val_mae: 0.2262\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 0.1076 - mae: 0.2439 - val_loss: 0.0770 - val_mae: 0.2338\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.1088 - mae: 0.2478 - val_loss: 0.0697 - val_mae: 0.2153\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.1102 - mae: 0.2480 - val_loss: 0.0718 - val_mae: 0.2259\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 2s 130ms/step - loss: 0.1082 - mae: 0.2486 - val_loss: 0.0721 - val_mae: 0.2165\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 2s 129ms/step - loss: 0.1064 - mae: 0.2438 - val_loss: 0.0674 - val_mae: 0.2185\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.1058 - mae: 0.2427 - val_loss: 0.0695 - val_mae: 0.2198\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.1045 - mae: 0.2410 - val_loss: 0.0668 - val_mae: 0.2171\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.1029 - mae: 0.2391 - val_loss: 0.0781 - val_mae: 0.2214\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.1106 - mae: 0.2454 - val_loss: 0.0983 - val_mae: 0.2420\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.1033 - mae: 0.2420 - val_loss: 0.0749 - val_mae: 0.2182\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.1114 - mae: 0.2505 - val_loss: 0.0698 - val_mae: 0.2153\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.1041 - mae: 0.2402 - val_loss: 0.0760 - val_mae: 0.2318\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 0.1065 - mae: 0.2457 - val_loss: 0.0705 - val_mae: 0.2155\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.1049 - mae: 0.2422 - val_loss: 0.0684 - val_mae: 0.2196\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.1074 - mae: 0.2456 - val_loss: 0.0653 - val_mae: 0.2131\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.1092 - mae: 0.2475 - val_loss: 0.0681 - val_mae: 0.2125\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.1030 - mae: 0.2386 - val_loss: 0.0987 - val_mae: 0.2635\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.1205 - mae: 0.2698 - val_loss: 0.0963 - val_mae: 0.2584\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.1176 - mae: 0.2623 - val_loss: 0.1155 - val_mae: 0.2639\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.1062 - mae: 0.2421 - val_loss: 0.0661 - val_mae: 0.2157\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.1046 - mae: 0.2405 - val_loss: 0.0822 - val_mae: 0.2260\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.1058 - mae: 0.2457 - val_loss: 0.0661 - val_mae: 0.2163\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.1013 - mae: 0.2389 - val_loss: 0.0680 - val_mae: 0.2145\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.1047 - mae: 0.2442 - val_loss: 0.0688 - val_mae: 0.2110\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0978 - mae: 0.2354 - val_loss: 0.0774 - val_mae: 0.2210\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.1018 - mae: 0.2386 - val_loss: 0.0672 - val_mae: 0.2149\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 2s 132ms/step - loss: 0.0981 - mae: 0.2339 - val_loss: 0.0637 - val_mae: 0.2095\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.1004 - mae: 0.2366 - val_loss: 0.0739 - val_mae: 0.2238\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.1010 - mae: 0.2398 - val_loss: 0.0814 - val_mae: 0.2357\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.1014 - mae: 0.2393 - val_loss: 0.0645 - val_mae: 0.2108\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.0973 - mae: 0.2341 - val_loss: 0.0714 - val_mae: 0.2134\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 2s 133ms/step - loss: 0.1001 - mae: 0.2353 - val_loss: 0.0781 - val_mae: 0.2336\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.0976 - mae: 0.2359 - val_loss: 0.0642 - val_mae: 0.2138\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0993 - mae: 0.2403 - val_loss: 0.0699 - val_mae: 0.2117\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0951 - mae: 0.2306 - val_loss: 0.0628 - val_mae: 0.2104\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.0964 - mae: 0.2316 - val_loss: 0.0661 - val_mae: 0.2092\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0960 - mae: 0.2322 - val_loss: 0.0641 - val_mae: 0.2062\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.0963 - mae: 0.2334 - val_loss: 0.0637 - val_mae: 0.2123\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.0944 - mae: 0.2316 - val_loss: 0.0657 - val_mae: 0.2075\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.0955 - mae: 0.2309 - val_loss: 0.0683 - val_mae: 0.2172\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0937 - mae: 0.2317 - val_loss: 0.0625 - val_mae: 0.2085\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.0937 - mae: 0.2289 - val_loss: 0.0654 - val_mae: 0.2071\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.0966 - mae: 0.2321 - val_loss: 0.0640 - val_mae: 0.2067\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0930 - mae: 0.2294 - val_loss: 0.0643 - val_mae: 0.2130\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.0912 - mae: 0.2252 - val_loss: 0.0632 - val_mae: 0.2083\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0926 - mae: 0.2288 - val_loss: 0.0754 - val_mae: 0.2144\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0948 - mae: 0.2299 - val_loss: 0.0611 - val_mae: 0.2044\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 2s 136ms/step - loss: 0.0905 - mae: 0.2255 - val_loss: 0.0609 - val_mae: 0.2017\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.0967 - mae: 0.2336 - val_loss: 0.0631 - val_mae: 0.2119\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0944 - mae: 0.2317 - val_loss: 0.0743 - val_mae: 0.2167\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.0935 - mae: 0.2303 - val_loss: 0.0639 - val_mae: 0.2131\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0906 - mae: 0.2246 - val_loss: 0.0593 - val_mae: 0.2040\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0878 - mae: 0.2202 - val_loss: 0.0606 - val_mae: 0.2048\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0878 - mae: 0.2231 - val_loss: 0.0600 - val_mae: 0.2085\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0908 - mae: 0.2256 - val_loss: 0.0592 - val_mae: 0.2021\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0882 - mae: 0.2218 - val_loss: 0.0623 - val_mae: 0.2022\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0867 - mae: 0.2199 - val_loss: 0.0582 - val_mae: 0.2018\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0880 - mae: 0.2236 - val_loss: 0.0633 - val_mae: 0.2092\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0863 - mae: 0.2206 - val_loss: 0.0597 - val_mae: 0.1981\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0893 - mae: 0.2261 - val_loss: 0.0709 - val_mae: 0.2205\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0954 - mae: 0.2360 - val_loss: 0.0582 - val_mae: 0.1969\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0908 - mae: 0.2275 - val_loss: 0.0590 - val_mae: 0.2023\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0864 - mae: 0.2204 - val_loss: 0.0581 - val_mae: 0.1990\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0846 - mae: 0.2168 - val_loss: 0.0660 - val_mae: 0.2060\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0892 - mae: 0.2260 - val_loss: 0.0580 - val_mae: 0.1990\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0858 - mae: 0.2206 - val_loss: 0.0693 - val_mae: 0.2186\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0855 - mae: 0.2192 - val_loss: 0.0574 - val_mae: 0.1965\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0916 - mae: 0.2284 - val_loss: 0.0575 - val_mae: 0.1967\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0858 - mae: 0.2225 - val_loss: 0.0636 - val_mae: 0.2100\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0880 - mae: 0.2234 - val_loss: 0.0557 - val_mae: 0.1992\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0869 - mae: 0.2224 - val_loss: 0.0599 - val_mae: 0.2028\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0828 - mae: 0.2171 - val_loss: 0.0602 - val_mae: 0.1955\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0834 - mae: 0.2188 - val_loss: 0.0668 - val_mae: 0.2052\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0871 - mae: 0.2219 - val_loss: 0.0655 - val_mae: 0.2128\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 0.0862 - mae: 0.2210 - val_loss: 0.0559 - val_mae: 0.1945\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0923 - mae: 0.2297 - val_loss: 0.0625 - val_mae: 0.2058\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0884 - mae: 0.2243 - val_loss: 0.0677 - val_mae: 0.2150\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 1s 68ms/step - loss: 0.0857 - mae: 0.2241 - val_loss: 0.0548 - val_mae: 0.1935\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.0781 - mae: 0.2103 - val_loss: 0.0868 - val_mae: 0.2525\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.0925 - mae: 0.2306 - val_loss: 0.0645 - val_mae: 0.2074\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.0776 - mae: 0.2081 - val_loss: 0.0559 - val_mae: 0.1957\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.0806 - mae: 0.2146 - val_loss: 0.0630 - val_mae: 0.1972\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0792 - mae: 0.2099 - val_loss: 0.0578 - val_mae: 0.1937\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0805 - mae: 0.2156 - val_loss: 0.0666 - val_mae: 0.2150\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.0796 - mae: 0.2156 - val_loss: 0.0548 - val_mae: 0.1995\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.0813 - mae: 0.2169 - val_loss: 0.0739 - val_mae: 0.2148\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.0834 - mae: 0.2163 - val_loss: 0.0530 - val_mae: 0.1930\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.0769 - mae: 0.2119 - val_loss: 0.0548 - val_mae: 0.1884\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 2s 125ms/step - loss: 0.0803 - mae: 0.2165 - val_loss: 0.0575 - val_mae: 0.1878\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0782 - mae: 0.2116 - val_loss: 0.0581 - val_mae: 0.1975\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 1s 66ms/step - loss: 0.0767 - mae: 0.2072 - val_loss: 0.0521 - val_mae: 0.1849\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 0.0729 - mae: 0.2019 - val_loss: 0.0602 - val_mae: 0.1997\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.0810 - mae: 0.2188 - val_loss: 0.0635 - val_mae: 0.2061\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0743 - mae: 0.2052 - val_loss: 0.0593 - val_mae: 0.1926\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.0759 - mae: 0.2121 - val_loss: 0.0520 - val_mae: 0.1899\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.0735 - mae: 0.2044 - val_loss: 0.0519 - val_mae: 0.1825\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.0759 - mae: 0.2065 - val_loss: 0.0598 - val_mae: 0.1906\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 0.0796 - mae: 0.2159 - val_loss: 0.0604 - val_mae: 0.1928\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.1021 - mae: 0.2450 - val_loss: 0.1402 - val_mae: 0.3284\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0940 - mae: 0.2366 - val_loss: 0.0622 - val_mae: 0.2034\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0780 - mae: 0.2140 - val_loss: 0.0579 - val_mae: 0.1886\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 2s 132ms/step - loss: 0.0722 - mae: 0.2039 - val_loss: 0.0533 - val_mae: 0.1809\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.0822 - mae: 0.2176 - val_loss: 0.0536 - val_mae: 0.1995\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0730 - mae: 0.2047 - val_loss: 0.0518 - val_mae: 0.1866\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.0704 - mae: 0.2010 - val_loss: 0.0603 - val_mae: 0.1996\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 2s 130ms/step - loss: 0.0783 - mae: 0.2114 - val_loss: 0.0543 - val_mae: 0.1886\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0892 - mae: 0.2265 - val_loss: 0.1247 - val_mae: 0.3084\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.1037 - mae: 0.2549 - val_loss: 0.0610 - val_mae: 0.1935\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 1s 97ms/step - loss: 0.0777 - mae: 0.2176 - val_loss: 0.0525 - val_mae: 0.1840\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 1s 84ms/step - loss: 0.0682 - mae: 0.1949 - val_loss: 0.0541 - val_mae: 0.1905\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.0696 - mae: 0.1979 - val_loss: 0.0497 - val_mae: 0.1788\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.0674 - mae: 0.1972 - val_loss: 0.0512 - val_mae: 0.1786\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.0710 - mae: 0.2031 - val_loss: 0.0788 - val_mae: 0.2232\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 1s 109ms/step - loss: 0.0743 - mae: 0.2047 - val_loss: 0.0605 - val_mae: 0.1966\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 2s 105ms/step - loss: 0.0732 - mae: 0.2015 - val_loss: 0.0641 - val_mae: 0.2119\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 0.0670 - mae: 0.1969 - val_loss: 0.0504 - val_mae: 0.1781\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.0701 - mae: 0.2002 - val_loss: 0.0521 - val_mae: 0.1895\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.0644 - mae: 0.1936 - val_loss: 0.0602 - val_mae: 0.1941\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0687 - mae: 0.1997 - val_loss: 0.0460 - val_mae: 0.1782\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0675 - mae: 0.1948 - val_loss: 0.0527 - val_mae: 0.1855\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.2080 - val_loss: 0.0482 - val_mae: 0.1779\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0624 - mae: 0.1901 - val_loss: 0.0475 - val_mae: 0.1718\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.1937 - val_loss: 0.0479 - val_mae: 0.1859\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0679 - mae: 0.1952 - val_loss: 0.0697 - val_mae: 0.2216\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0819 - mae: 0.2151 - val_loss: 0.0858 - val_mae: 0.2491\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0885 - mae: 0.2293 - val_loss: 0.0624 - val_mae: 0.2055\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0661 - mae: 0.1979 - val_loss: 0.0452 - val_mae: 0.1720\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0646 - mae: 0.1946 - val_loss: 0.0628 - val_mae: 0.2070\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0633 - mae: 0.1897 - val_loss: 0.0435 - val_mae: 0.1696\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0700 - mae: 0.1993 - val_loss: 0.0800 - val_mae: 0.2267\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0816 - mae: 0.2219 - val_loss: 0.0893 - val_mae: 0.2404\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0817 - mae: 0.2206 - val_loss: 0.0472 - val_mae: 0.1698\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - mae: 0.1870 - val_loss: 0.0422 - val_mae: 0.1694\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0653 - mae: 0.1960 - val_loss: 0.0606 - val_mae: 0.2050\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.1982 - val_loss: 0.0656 - val_mae: 0.2138\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0612 - mae: 0.1875 - val_loss: 0.0430 - val_mae: 0.1712\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0579 - mae: 0.1833 - val_loss: 0.0484 - val_mae: 0.1790\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - mae: 0.1902 - val_loss: 0.0594 - val_mae: 0.2054\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0594 - mae: 0.1875 - val_loss: 0.0448 - val_mae: 0.1677\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0558 - mae: 0.1801 - val_loss: 0.0521 - val_mae: 0.1824\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0658 - mae: 0.1982 - val_loss: 0.0724 - val_mae: 0.2144\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0731 - mae: 0.2053 - val_loss: 0.0510 - val_mae: 0.1801\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 1s 59ms/step - loss: 0.0595 - mae: 0.1859 - val_loss: 0.0681 - val_mae: 0.2087\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0692 - mae: 0.2015 - val_loss: 0.0493 - val_mae: 0.1834\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0571 - mae: 0.1817 - val_loss: 0.0482 - val_mae: 0.1829\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0649 - mae: 0.1975 - val_loss: 0.0420 - val_mae: 0.1687\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0578 - mae: 0.1827 - val_loss: 0.0421 - val_mae: 0.1715\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0552 - mae: 0.1797 - val_loss: 0.0875 - val_mae: 0.2545\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0751 - mae: 0.2164 - val_loss: 0.0628 - val_mae: 0.2105\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0543 - mae: 0.1792 - val_loss: 0.0425 - val_mae: 0.1668\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0513 - mae: 0.1723 - val_loss: 0.0421 - val_mae: 0.1661\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0533 - mae: 0.1759 - val_loss: 0.0417 - val_mae: 0.1638\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0524 - mae: 0.1746 - val_loss: 0.0440 - val_mae: 0.1719\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0525 - mae: 0.1756 - val_loss: 0.0585 - val_mae: 0.2036\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0513 - mae: 0.1733 - val_loss: 0.0434 - val_mae: 0.1628\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0574 - mae: 0.1841 - val_loss: 0.0479 - val_mae: 0.1725\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0499 - mae: 0.1701 - val_loss: 0.0373 - val_mae: 0.1592\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0493 - mae: 0.1697 - val_loss: 0.0381 - val_mae: 0.1588\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.0505 - mae: 0.1716 - val_loss: 0.0381 - val_mae: 0.1588\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 0.0621 - mae: 0.1893 - val_loss: 0.0440 - val_mae: 0.1759\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 1s 35ms/step - loss: 0.0627 - mae: 0.1943 - val_loss: 0.0412 - val_mae: 0.1712\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 1s 71ms/step - loss: 0.0533 - mae: 0.1770 - val_loss: 0.0381 - val_mae: 0.1607\n",
      "Epoch 459/500\n",
      " 2/14 [===>..........................] - ETA: 1s - loss: 0.0369 - mae: 0.1584"
     ]
    }
   ],
   "source": [
    "history = ann.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val),\n",
    "                    callbacks=[es],\n",
    "                    epochs=500,\n",
    "                    batch_size=30,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# let's see the training and validation accuracy by epoch\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss'] # you can change this\n",
    "val_loss_values = history_dict['val_loss'] # you can also change this\n",
    "epochs = range(1, len(loss_values) + 1) # range of X (no. of epochs)\n",
    "\n",
    "# Set global font to Times New Roman and font size\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(epochs, loss_values, 'blue', label='Train set')\n",
    "plt.plot(epochs, val_loss_values, 'orange', label='Validation set')\n",
    "#plt.title('Training and testing loss')\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.savefig('Change_ANN1_2.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "loss_values1 = history_dict['mae'] # you can change this\n",
    "val_loss_values1 = history_dict['val_mae'] # you can also change this\n",
    "epochs = range(1, len(loss_values1) + 1) # range of X (no. of epochs)\n",
    "# Create a plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(epochs, loss_values1, 'blue', label='Train set')\n",
    "plt.plot(epochs, val_loss_values1, 'orange', label='Validation set')\n",
    "#plt.title('Training and testing MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE (kPa)')\n",
    "plt.legend()\n",
    "plt.savefig('Change_ANN1_3.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ann.save('Change_ANN_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# scatterplot of actual vs. pred\n",
    "# specify the dimensions \n",
    "fig, axes = plt.subplots(1,2) # 1 row, 2 columns\n",
    "\n",
    "# this makes the individual subplots\n",
    "# Training Results\n",
    "axes[0].scatter(x=y_train, y=ann.predict(X_train)) #first row, first entry (left top)\n",
    "axes[0].set_xlabel(\"Actual\", fontsize=10)\n",
    "axes[0].set_ylabel(\"Predicted\",  fontsize=10)\n",
    "axes[0].set_title(\"Training\")\n",
    "# add 45 deg line\n",
    "x = np.linspace(*axes[0].get_xlim())\n",
    "axes[0].plot(x, x, color='red')\n",
    "# Validation Results\n",
    "axes[1].scatter(x=y_val, y=ann.predict(X_val)) # first row, second entry (right top)\n",
    "axes[1].set_xlabel(\"Actual\", fontsize=10)\n",
    "axes[1].set_ylabel(\"Predicted\",  fontsize=10)\n",
    "axes[1].set_title(\"Validation\")\n",
    "# add 45 deg line\n",
    "x = np.linspace(*axes[1].get_xlim())\n",
    "axes[1].plot(x, x, color='red')\n",
    "\n",
    "# tight layout\n",
    "fig.tight_layout()\n",
    "plt.savefig('Change_ANN1_1.png', dpi=200, bbox_inches='tight')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "IA0yApEmBG1X",
    "outputId": "cb981e1f-9204-4a2a-fece-9d66a6919189",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_test, y_pred, color=\"blue\")\n",
    "plt.xlabel ('Actual data')\n",
    "plt.ylabel ('Predicted data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Initialize layout\n",
    "fig1, ax1 = plt.subplots(figsize = (6, 6))\n",
    "\n",
    "b_l = -30\n",
    "u_l = 150\n",
    "\n",
    "# Add scatterplot\n",
    "ax1.scatter(y_test, y_pred, s=70, alpha=1, edgecolors=\"k\",c='mediumblue',zorder=5, label = 'Points')\n",
    "\n",
    "\n",
    "plt.ylabel('Predicted Change Time (ms)')\n",
    "plt.xlabel('Target Change Time (ms)')\n",
    "plt.xticks(fontsize = 19)\n",
    "plt.yticks(fontsize = 19)\n",
    "\n",
    "\n",
    "x1 = np.linspace(b_l, u_l)\n",
    "\n",
    "plt.plot(x1, x1, 'Red', label='45\\N{DEGREE SIGN} line',lw=2.5,alpha=1)\n",
    "\n",
    "plt.ylim(b_l, u_l)\n",
    "plt.xlim(b_l, u_l)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=4, frameon = False, fontsize = 20)\n",
    "\n",
    "#plt.grid()\n",
    "\n",
    "ax1.spines['left'].set_color('black')        # setting up Y-axis tick color to red\n",
    "ax1.spines['bottom'].set_color('black')         #setting up above X-axis tick color to red\n",
    "\n",
    "plt.savefig('Change_ANN1.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "trainpreds = ann.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_train, trainpreds)) # train\n",
    "print(mean_absolute_error(y_test, y_pred)) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print (r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "r2_train = r2_score(y_train, trainpreds)\n",
    "print (r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "count0 = 0\n",
    "for i in range(len(y_pred)):\n",
    "    line1 = y_pred[i] - 0.95*y_test[i]\n",
    "    line2 = y_pred[i] - 1.05*y_test[i]\n",
    "    mask0 = (line1 > 0) & (line2 < 0)\n",
    "    count0 = np.sum(mask0+count0)\n",
    "\n",
    "count1 = 0\n",
    "for i in range(len(y_pred)):\n",
    "    line1 = y_pred[i] - 0.9*y_test[i]\n",
    "    line2 = y_pred[i] - 1.1*y_test[i]\n",
    "    mask1 = (line1 > 0) & (line2 < 0)\n",
    "    count1 = np.sum(mask1+count1)\n",
    "\n",
    "count2 = 0\n",
    "for j in range(len(y_pred)):\n",
    "    line3 = y_pred[j] - 0.8*y_test[j]\n",
    "    line4 = y_pred[j] - 1.2*y_test[j]\n",
    "    mask2 = (line3 > 0) & (line4 < 0)\n",
    "    count2 = np.sum(mask2+count2)\n",
    "\n",
    "\n",
    "count3 = 0    \n",
    "for k in range(len(y_pred)):\n",
    "    line5 = y_pred[k] - 0.8*y_test[k]\n",
    "    line6 = y_pred[k] - 1.2*y_test[k]\n",
    "    mask3 = (line5 < 0) or (line6 > 0)\n",
    "    count3 = np.sum(mask3+count3)\n",
    "   \n",
    "\n",
    "print ('Within 5% margin', format((count0/len (y_pred)),'.2%'))\n",
    "print ('Within 10% margin', format((count1/len (y_pred)),'.2%'))\n",
    "print ('Within 20% margin', format((count2/len (y_pred)),'.2%'))\n",
    "print ('Out of 20% margin', format((count3/len (y_pred)),'.2%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "adj_r2 = 1 - ((1 - r2) * (len(X_test) - 1) / (len(X_test) - len (X_test[0]) - 1))\n",
    "print (adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
