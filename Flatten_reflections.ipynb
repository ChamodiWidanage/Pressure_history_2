{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T00:33:21.790680Z",
     "start_time": "2024-07-17T00:33:05.825415200Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from pathlib import Path\n",
    "import xlwings as xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame for all times\n",
    "df_all = pd.DataFrame(columns=[\"Mass\", \"Standoff distance\", \"Angle\", \"Arrival time\", \"Change time\", \"Trough time\", \"End time\"])\n",
    "\n",
    "# Mapping dictionary\n",
    "mapping = {\"1\": 0, \"2\": 15, \"3\": 30, \"4\": 45, \"5\": 60}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T01:42:58.385593400Z",
     "start_time": "2024-07-17T01:42:58.368942900Z"
    }
   },
   "id": "ac042f4e2c7a80b2"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_excel7m\n",
      "2 [WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m00.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m02.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m04.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m06.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m08.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m10.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m12.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m14.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m16.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m18.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m20.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m22.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m24.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m26.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m28.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m30.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m32.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m34.5kg'), WindowsPath('G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m/07m35.0kg')]\n"
     ]
    }
   ],
   "source": [
    "#Access input folder\n",
    "input_dir1 = Path (\"G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_excel7m\")\n",
    "print (\"1\",input_dir1)\n",
    "\n",
    "#Access folders inside input folder\n",
    "input_dir2 =  [folder for folder in input_dir1.iterdir() if folder.is_dir()]\n",
    "print (\"2\",input_dir2)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"G:/Chamodi/LSDYNA3D/RP_TH_models/RP_curves_fr7m\")\n",
    "output_dir.mkdir(exist_ok = True)\n",
    "\n",
    "# Define current work directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Access the template to be used to generate files\n",
    "excel_template = current_dir/ \"Template.xlsx\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T01:42:59.788981700Z",
     "start_time": "2024-07-17T01:42:59.775411500Z"
    }
   },
   "id": "cdd9ff3084c8fc77"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Identify peaks with tolerance parameters\n",
    "height_threshold = 2  # Minimum height of peaks to detect\n",
    "prominence = 0.01  # Minimum prominence of peaks in pressure units\n",
    "width = 8  # Minimum width of peaks in time units"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T01:43:08.775243300Z",
     "start_time": "2024-07-17T01:43:08.759696Z"
    }
   },
   "id": "9ab4b896af6af8c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Determine peak before smoothing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ae7196339b150a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m00.5kg\n",
      "1 0\n",
      "247 31 154 1120\n",
      "file_name 1\n",
      "2 15\n",
      "240 75 186 1102\n",
      "file_name 2\n",
      "3 30\n",
      "Less than one peaks found in the data.\n",
      "file_name 3\n",
      "4 45\n",
      "Less than one peaks found in the data.\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m02.5kg\n",
      "1 0\n",
      "280 186 229 538\n",
      "file_name 1\n",
      "2 15\n",
      "272 171 221 532\n",
      "file_name 2\n",
      "3 30\n",
      "244 179 505 1207\n",
      "file_name 3\n",
      "4 45\n",
      "203 263 435 977\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m04.5kg\n",
      "1 0\n",
      "304 239 597 639\n",
      "file_name 1\n",
      "2 15\n",
      "293 210 241 556\n",
      "file_name 2\n",
      "3 30\n",
      "258 206 530 1309\n",
      "file_name 3\n",
      "4 45\n",
      "211 275 453 1069\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m06.5kg\n",
      "1 0\n",
      "337 468 638 678\n",
      "file_name 1\n",
      "2 15\n",
      "324 236 272 592\n",
      "file_name 2\n",
      "3 30\n",
      "271 291 550 1385\n",
      "file_name 3\n",
      "4 45\n",
      "215 311 463 1137\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m08.5kg\n",
      "1 0\n",
      "375 490 686 719\n",
      "file_name 1\n",
      "2 15\n",
      "358 275 307 632\n",
      "file_name 2\n",
      "3 30\n",
      "290 357 574 1450\n",
      "file_name 3\n",
      "4 45\n",
      "219 340 472 1189\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m10.5kg\n",
      "1 0\n",
      "708 546 1002 1037\n",
      "file_name 1\n",
      "2 15\n",
      "683 311 344 957\n",
      "file_name 2\n",
      "3 30\n",
      "313 427 486 572\n",
      "file_name 3\n",
      "4 45\n",
      "223 370 481 1231\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m12.5kg\n",
      "1 0\n",
      "748 585 621 643\n",
      "file_name 1\n",
      "2 15\n",
      "721 344 376 998\n",
      "file_name 2\n",
      "3 30\n",
      "610 468 513 879\n",
      "file_name 3\n",
      "4 45\n",
      "268 393 488 716\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m14.5kg\n",
      "1 0\n",
      "788 627 667 693\n",
      "file_name 1\n",
      "2 15\n",
      "759 375 636 1038\n",
      "file_name 2\n",
      "3 30\n",
      "639 506 545 911\n",
      "file_name 3\n",
      "4 45\n",
      "322 419 495 728\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m16.5kg\n",
      "1 0\n",
      "827 669 720 743\n",
      "file_name 1\n",
      "2 15\n",
      "796 399 707 1077\n",
      "file_name 2\n",
      "3 30\n",
      "667 536 570 942\n",
      "file_name 3\n",
      "4 45\n",
      "328 444 505 542\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m18.5kg\n",
      "1 0\n",
      "863 578 605 786\n",
      "file_name 1\n",
      "2 15\n",
      "830 419 751 1113\n",
      "file_name 2\n",
      "3 30\n",
      "695 567 611 973\n",
      "file_name 3\n",
      "4 45\n",
      "496 586 775 808\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m20.5kg\n",
      "1 0\n",
      "897 None 607 826\n",
      "file_name 1\n",
      "2 15\n",
      "864 438 789 1146\n",
      "file_name 2\n",
      "3 30\n",
      "722 539 1024 1759\n",
      "file_name 3\n",
      "4 45\n",
      "508 614 790 821\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m22.5kg\n",
      "1 0\n",
      "932 None 635 866\n",
      "file_name 1\n",
      "2 15\n",
      "895 455 823 1179\n",
      "file_name 2\n",
      "3 30\n",
      "749 592 1054 1794\n",
      "file_name 3\n",
      "4 45\n",
      "520 633 804 836\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m24.5kg\n",
      "1 0\n",
      "928 None 624 869\n",
      "file_name 1\n",
      "2 15\n",
      "890 436 822 1175\n",
      "file_name 2\n",
      "3 30\n",
      "766 619 1074 1361\n",
      "file_name 3\n",
      "4 45\n",
      "534 619 820 852\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m26.5kg\n",
      "1 0\n",
      "931 613 620 880\n",
      "file_name 1\n",
      "2 15\n",
      "900 431 834 1186\n",
      "file_name 2\n",
      "3 30\n",
      "785 647 1096 1837\n",
      "file_name 3\n",
      "4 45\n",
      "547 637 836 868\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m28.5kg\n",
      "1 0\n",
      "945 604 627 665\n",
      "file_name 1\n",
      "2 15\n",
      "915 431 864 1203\n",
      "file_name 2\n",
      "3 30\n",
      "804 677 1117 1861\n",
      "file_name 3\n",
      "4 45\n",
      "561 666 853 886\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m30.5kg\n",
      "1 0\n",
      "960 601 634 674\n",
      "file_name 1\n",
      "2 15\n",
      "930 433 879 1221\n",
      "file_name 2\n",
      "3 30\n",
      "820 699 1136 1379\n",
      "file_name 3\n",
      "4 45\n",
      "575 681 871 904\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m32.5kg\n",
      "1 0\n",
      "971 598 639 680\n",
      "file_name 1\n",
      "2 15\n",
      "943 433 892 1237\n",
      "file_name 2\n",
      "3 30\n",
      "836 710 1155 1400\n",
      "file_name 3\n",
      "4 45\n",
      "591 701 887 920\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m34.5kg\n",
      "1 0\n",
      "983 606 643 685\n",
      "file_name 1\n",
      "2 15\n",
      "954 434 903 1253\n",
      "file_name 2\n",
      "3 30\n",
      "849 734 1171 1224\n",
      "file_name 3\n",
      "4 45\n",
      "606 720 904 938\n",
      "file_name 4\n",
      "output_dir1 G:\\Chamodi\\LSDYNA3D\\RP_TH_models\\RP_curves_fr7m\\07m35.0kg\n",
      "1 0\n",
      "984 603 643 685\n",
      "file_name 1\n",
      "2 15\n",
      "957 434 906 1258\n",
      "file_name 2\n",
      "3 30\n",
      "852 783 1175 1228\n",
      "file_name 3\n",
      "4 45\n",
      "610 725 909 942\n",
      "file_name 4\n"
     ]
    }
   ],
   "source": [
    "for folder in input_dir2:\n",
    "    \n",
    "    SD = int(folder.name[0:2])\n",
    "    EM = float(folder.name[3:-2])\n",
    "    \n",
    "    # Make a list of data file names\n",
    "    #files = [file for file in folder.rglob(\"*\")]\n",
    "    files = [file for file in folder.rglob(\"*\") if \"5\" not in file.stem]\n",
    "    \n",
    "    # Create output folders\n",
    "    output_dir1 = output_dir/ folder.name\n",
    "    print (\"output_dir1\", output_dir1)\n",
    "    output_dir1.mkdir(exist_ok = True)\n",
    "    \n",
    "    # Initiate xlwings library\n",
    "    with xw.App (visible = False) as app:\n",
    "        \n",
    "        # Access each file \n",
    "        for file in files:\n",
    "            \n",
    "            # Assign value to A based on file.stem\n",
    "            file_name = file.stem\n",
    "            A = mapping.get(file_name, None)\n",
    "            print(file_name, A)\n",
    "\n",
    "            # Open excel template\n",
    "            wb = app.books.open(excel_template)\n",
    "            \n",
    "            # Read data from Excel file\n",
    "            df = pd.read_excel(file)\n",
    "            \n",
    "            # Extract time and pressure columns\n",
    "            time = df.iloc[:, 0].values\n",
    "            pressure = df.iloc[:, 1].values\n",
    "            pressure -= 0.18\n",
    "            \n",
    "            # Find the index of the peak value\n",
    "            peak_index = np.argmax(pressure)\n",
    "            \n",
    "            pressure = pressure[peak_index:]\n",
    "            time = time[peak_index:]\n",
    "            \n",
    "            # Find peaks\n",
    "            peaks, properties = find_peaks(pressure, height=height_threshold, prominence=prominence, width=width)\n",
    "            \n",
    "            # Ensure there are at least two peaks\n",
    "            if len(peaks) >= 1:\n",
    "                #first_peak_index = peaks[0]\n",
    "            \n",
    "                # Create a copy of pressure data to modify\n",
    "                smoothed_pressure = np.copy(pressure)\n",
    "            \n",
    "                # Define a window around each peak after the first peak to apply smoothing\n",
    "                window_radius_r = 100\n",
    "                window_radius_l = 50 # Adjust the window radius as needed\n",
    "            \n",
    "                for peak_index in peaks[:]:\n",
    "                    start = max(peak_index - window_radius_l, 0)\n",
    "                    end = min(peak_index + window_radius_r + 1, len(pressure))\n",
    "            \n",
    "                    # Extract values just outside the window\n",
    "                    if start > 0 and end < len(pressure):\n",
    "                        start_value = pressure[start - 1]\n",
    "                        end_value = pressure[end]\n",
    "                    elif start > 0:\n",
    "                        start_value = pressure[start - 1]\n",
    "                        end_value = start_value\n",
    "                    elif end < len(pressure):\n",
    "                        end_value = pressure[end]\n",
    "                        start_value = end_value\n",
    "                    else:\n",
    "                        start_value = end_value = np.mean(pressure)  # Fallback in case there are no valid points\n",
    "            \n",
    "                    # Create a linearly spaced array between start_value and end_value\n",
    "                    interpolated_values = np.linspace(start_value, end_value, end - start)\n",
    "            \n",
    "                    # Apply the interpolated values to the points within the window\n",
    "                    smoothed_pressure[start:end] = interpolated_values\n",
    "                \n",
    "                # Find the index of the peak value\n",
    "                #peak_index = np.argmax(smoothed_pressure)\n",
    "                \n",
    "                # Find the index of the lowest (most negative) value after the peak\n",
    "                lowest_index = np.argmin(smoothed_pressure[:])\n",
    "                \n",
    "                if smoothed_pressure[lowest_index] < 0:\n",
    "                    \n",
    "                    # Find the first zero crossing between peak and lowest value\n",
    "                    zero_crossing_index_1 = next((i for i, val in enumerate(smoothed_pressure[:lowest_index], start=0) if val <= 0), None)\n",
    "                \n",
    "                    # Find the first zero crossing after the lowest value\n",
    "                    zero_crossing_index_2 = next((i for i, val in enumerate(smoothed_pressure[lowest_index:], start=lowest_index) if val >= 0), None)\n",
    "                    \n",
    "                    if zero_crossing_index_2 is None:\n",
    "                        zero_crossing_index_2 = min(range(lowest_index, len(smoothed_pressure)),key=lambda i: abs(smoothed_pressure[i]))\n",
    "                    \n",
    "                else:                        \n",
    "                        \n",
    "                    zero_crossing_index_1 = lowest_index\n",
    "                    zero_crossing_index_2 = lowest_index\n",
    "                    \n",
    "                # Find the peak (maximum) values of each array\n",
    "                max_pressure = np.max(pressure)\n",
    "                max_smoothed_pressure = np.max(smoothed_pressure)\n",
    "                \n",
    "                # Check if the peak values are the same\n",
    "                if max_pressure == max_smoothed_pressure:\n",
    "                \n",
    "                    # Arrival, change, trough and end times\n",
    "                    AT = time[0]\n",
    "                    CT = time[zero_crossing_index_1]\n",
    "                    TT = time[lowest_index]\n",
    "                    ET = time[zero_crossing_index_2]\n",
    "                    print (peak_index, zero_crossing_index_1, lowest_index, zero_crossing_index_2)\n",
    "                    \n",
    "                    # Append the values to DataFrames\n",
    "                    # Creating a new DataFrame to append\n",
    "                    row_all = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"Arrival time\": [AT], \"Change time\": [CT], \"Trough time\": [TT], \"End time\": [ET]})\n",
    "                    df_all = pd.concat([df_all, row_all], ignore_index=True)\n",
    "                    \n",
    "                    # Create a dictionary with the arrays\n",
    "                    data1 = {'Time': time,\n",
    "                            'Smoothed_Pressure': smoothed_pressure,\n",
    "                            'Pressure': pressure}\n",
    "                    data2 = {'Adj Time': time[: zero_crossing_index_2+1],\n",
    "                            'Adj Pressure': smoothed_pressure[: zero_crossing_index_2+1]}\n",
    "                    \n",
    "                    # Create DataFrames from dictionaries\n",
    "                    df1 = pd.DataFrame(data1)\n",
    "                    df2 = pd.DataFrame(data2)\n",
    "                    \n",
    "                    # Concatenate DataFrames along the columns\n",
    "                    df_combined = pd.concat([df1, df2], axis=1)\n",
    "                    \n",
    "                    # Create a DataFrame from the dictionary\n",
    "                    df3 = pd.DataFrame(df_combined)\n",
    "                    \n",
    "                    # Write dataframe in excel template\n",
    "                    wb.sheets[0].range(\"A1\").options(index=False).value = df3\n",
    "                    \n",
    "                    print (\"file_name\",file_name)\n",
    "                    \n",
    "                    # Create files in output directory\n",
    "                    wb.save(output_dir1/f\"{file_name}.xlsx\")\n",
    "                \n",
    "                else:\n",
    "                    print(\"The peak values are different.\")\n",
    "                \n",
    "            else:\n",
    "                print(\"Less than one peaks found in the data.\")\n",
    "                \n",
    "                # Create a dictionary with the arrays\n",
    "                data3 = {'Time': time,'Pressure': pressure}\n",
    "                \n",
    "                # Create a DataFrame from the dictionary\n",
    "                df4 = pd.DataFrame(data3)\n",
    "                \n",
    "                # Write dataframe in excel template\n",
    "                wb.sheets[0].range(\"A1\").options(index=False).value = df4\n",
    "                \n",
    "                print (\"file_name\",file_name)\n",
    "                \n",
    "                # Create files in output directory\n",
    "                wb.save(output_dir1/f\"{file_name}.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T01:45:46.730291800Z",
     "start_time": "2024-07-17T01:43:12.691010100Z"
    }
   },
   "id": "9ec474194628bb6f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Write dataframes in excel template\n",
    "all_path = 'RP_all.xlsx'\n",
    "\n",
    "df_all.to_excel(all_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T01:50:31.203521Z",
     "start_time": "2024-07-17T01:50:31.108541900Z"
    }
   },
   "id": "bcc07d2ffa0685b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Without smoothing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda95c3fc2a75ae0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in input_dir2:\n",
    "    \n",
    "    SD = int(folder.name[0:2])\n",
    "    EM = float(folder.name[3:-2])\n",
    "    \n",
    "    # Make a list of data file names\n",
    "    files = [file for file in folder.rglob(\"*\")]\n",
    "    \n",
    "    # Create output folders\n",
    "    output_dir1 = output_dir/ folder.name\n",
    "    print (\"output_dir1\", output_dir1)\n",
    "    output_dir1.mkdir(exist_ok = True)\n",
    "    \n",
    "    # Initiate xlwings library\n",
    "    with xw.App (visible = False) as app:\n",
    "        \n",
    "        # Access each file \n",
    "        for file in files:\n",
    "            \n",
    "            # Assign value to A based on file.stem\n",
    "            file_name = file.stem\n",
    "            A = mapping.get(file_name, None)\n",
    "            print(file_name, A)\n",
    "\n",
    "            # Open excel template\n",
    "            wb = app.books.open(excel_template)\n",
    "            \n",
    "            # Read data from Excel file\n",
    "            df = pd.read_excel(file)\n",
    "            \n",
    "            # Extract time and pressure columns\n",
    "            time = df.iloc[:, 0].values\n",
    "            pressure = df.iloc[:, 1].values\n",
    "             \n",
    "            # Find the index of the peak value\n",
    "            peak_index = np.argmax(pressure)\n",
    "            \n",
    "            # Filter array after peak value\n",
    "            adj_pressure = pressure[peak_index:]\n",
    "            adj_time = time[peak_index:]\n",
    "                \n",
    "            # Find the index of the lowest (most negative) value after the peak\n",
    "            lowest_index = np.argmin(adj_pressure)\n",
    "                \n",
    "            if adj_pressure[lowest_index] < 0:\n",
    "                    \n",
    "                # Find the first zero crossing between peak and lowest value\n",
    "                zero_crossing_index_1 = next((i for i, val in enumerate(adj_pressure[0:lowest_index], start=0) if val <= 0), None)\n",
    "                \n",
    "                # Find the first zero crossing after the lowest value\n",
    "                zero_crossing_index_2 = next((i for i, val in enumerate(adj_pressure[lowest_index:], start=lowest_index) if val >= 0), None)\n",
    "                    \n",
    "                if zero_crossing_index_2 is None:\n",
    "                    zero_crossing_index_2 = min(range(lowest_index, len(adj_pressure)),key=lambda i: abs(adj_pressure[i]))\n",
    "                    \n",
    "            else:                        \n",
    "                        \n",
    "                zero_crossing_index_1 = lowest_index\n",
    "                zero_crossing_index_2 = lowest_index\n",
    "                \n",
    "            # Arrival, change, trough and end times\n",
    "            AT = adj_time[0]\n",
    "            CT = adj_time[zero_crossing_index_1]\n",
    "            TT = adj_time[lowest_index]\n",
    "            ET = adj_time[zero_crossing_index_2]\n",
    "            print (peak_index, zero_crossing_index_1, lowest_index, zero_crossing_index_2)\n",
    "                \n",
    "            # Append the values to DataFrames\n",
    "            # Creating a new DataFrame to append\n",
    "            row_all = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"Arrival time\": [AT], \"Change time\": [CT], \"Trough time\": [TT], \"End time\": [ET]})\n",
    "            df_all = pd.concat([df_all, row_all], ignore_index=True)\n",
    "                \n",
    "            # Create a dictionary with the arrays\n",
    "            data1 = {'Time': time,\n",
    "                    'Pressure': pressure}\n",
    "            data2 = {'Adj Time': adj_time[0: zero_crossing_index_2+1],\n",
    "                    'Adj Pressure': adj_pressure[0: zero_crossing_index_2+1]}\n",
    "                \n",
    "            # Create DataFrames from dictionaries\n",
    "            df1 = pd.DataFrame(data1)\n",
    "            df2 = pd.DataFrame(data2)\n",
    "                \n",
    "            # Concatenate DataFrames along the columns\n",
    "            df_combined = pd.concat([df1, df2], axis=1)\n",
    "                \n",
    "            # Create a DataFrame from the dictionary\n",
    "            df3 = pd.DataFrame(df_combined)\n",
    "                \n",
    "            # Write dataframe in excel template\n",
    "            wb.sheets[0].range(\"A1\").options(index=False).value = df3\n",
    "                \n",
    "            print (\"file_name\",file_name)\n",
    "                \n",
    "            # Create files in output directory\n",
    "            wb.save(output_dir1/f\"{file_name}.xlsx\") "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d66989767edc10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3271eea380573fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for folder in input_dir2:\n",
    "    \n",
    "    SD = int(folder.name[0:2])\n",
    "    EM = float(folder.name[3:-2])\n",
    "    \n",
    "    # Make a list of data file names\n",
    "    files = [file for file in folder.rglob(\"*\")]\n",
    "    \n",
    "    # Create output folders\n",
    "    output_dir1 = output_dir/ folder.name\n",
    "    print (\"output_dir1\", output_dir1)\n",
    "    output_dir1.mkdir(exist_ok = True)\n",
    "    \n",
    "    # Initiate xlwings library\n",
    "    with xw.App (visible = False) as app:\n",
    "        \n",
    "        # Access each file \n",
    "        for file in files:\n",
    "            \n",
    "            # Assign value to A based on file.stem\n",
    "            file_name = file.stem\n",
    "            A = mapping.get(file_name, None)\n",
    "            print(file_name, A)\n",
    "\n",
    "            # Open excel template\n",
    "            wb = app.books.open(excel_template)\n",
    "            \n",
    "            # Read data from Excel file\n",
    "            df = pd.read_excel(file)\n",
    "            \n",
    "            # Extract time and pressure columns\n",
    "            time = df.iloc[:, 0].values\n",
    "            pressure = df.iloc[:, 1].values\n",
    "            \n",
    "            # Find peaks\n",
    "            peaks, properties = find_peaks(pressure, height=height_threshold, prominence=prominence, width=width)\n",
    "            \n",
    "            # Ensure there are at least two peaks\n",
    "            if len(peaks) >= 2:\n",
    "                first_peak_index = peaks[0]\n",
    "            \n",
    "                # Create a copy of pressure data to modify\n",
    "                smoothed_pressure = np.copy(pressure)\n",
    "            \n",
    "                # Define a window around each peak after the first peak to apply smoothing\n",
    "                window_radius_r = 20\n",
    "                window_radius_l = 20 # Adjust the window radius as needed\n",
    "            \n",
    "                for peak_index in peaks[1:]:\n",
    "                    start = max(peak_index - window_radius_l, 0)\n",
    "                    end = min(peak_index + window_radius_r + 1, len(pressure))\n",
    "            \n",
    "                    # Extract values just outside the window\n",
    "                    if start > 0 and end < len(pressure):\n",
    "                        start_value = pressure[start - 1]\n",
    "                        end_value = pressure[end]\n",
    "                    elif start > 0:\n",
    "                        start_value = pressure[start - 1]\n",
    "                        end_value = start_value\n",
    "                    elif end < len(pressure):\n",
    "                        end_value = pressure[end]\n",
    "                        start_value = end_value\n",
    "                    else:\n",
    "                        start_value = end_value = np.mean(pressure)  # Fallback in case there are no valid points\n",
    "            \n",
    "                    # Create a linearly spaced array between start_value and end_value\n",
    "                    interpolated_values = np.linspace(start_value, end_value, end - start)\n",
    "            \n",
    "                    # Apply the interpolated values to the points within the window\n",
    "                    smoothed_pressure[start:end] = interpolated_values\n",
    "                \n",
    "                # Find the index of the peak value\n",
    "                peak_index = np.argmax(smoothed_pressure)\n",
    "                \n",
    "                # Find the index of the lowest (most negative) value after the peak\n",
    "                lowest_index = peak_index + np.argmin(smoothed_pressure[peak_index:])\n",
    "                \n",
    "                if smoothed_pressure[lowest_index] < 0:\n",
    "                    \n",
    "                    # Find the first zero crossing between peak and lowest value\n",
    "                    zero_crossing_index_1 = next((i for i, val in enumerate(smoothed_pressure[peak_index:lowest_index], start=peak_index) if val <= 0), None)\n",
    "                \n",
    "                    # Find the first zero crossing after the lowest value\n",
    "                    zero_crossing_index_2 = next((i for i, val in enumerate(smoothed_pressure[lowest_index:], start=lowest_index) if val >= 0), None)\n",
    "                    \n",
    "                    if zero_crossing_index_2 is None:\n",
    "                        zero_crossing_index_2 = min(range(lowest_index, len(smoothed_pressure)),key=lambda i: abs(smoothed_pressure[i]))\n",
    "                    \n",
    "                else:                        \n",
    "                        \n",
    "                    zero_crossing_index_1 = lowest_index\n",
    "                    zero_crossing_index_2 = lowest_index\n",
    "                \n",
    "                # Arrival, change, trough and end times\n",
    "                AT = time[peak_index]\n",
    "                CT = time[zero_crossing_index_1]\n",
    "                TT = time[lowest_index]\n",
    "                ET = time[zero_crossing_index_2]\n",
    "                print (peak_index, zero_crossing_index_1, lowest_index, zero_crossing_index_2)\n",
    "                \n",
    "                # Append the values to DataFrames\n",
    "                # Creating a new DataFrame to append\n",
    "                row_arrival = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"Arrival time\": [AT]})\n",
    "                df_arrival = pd.concat([df_arrival, row_arrival], ignore_index=True)\n",
    "                row_change = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"Change time\": [CT]})\n",
    "                df_change = pd.concat([df_change, row_change], ignore_index=True)\n",
    "                row_trough = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"Trough time\": [TT]})\n",
    "                df_trough = pd.concat([df_trough, row_trough], ignore_index=True)\n",
    "                row_end = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"End time\": [ET]})\n",
    "                df_end = pd.concat([df_end, row_end], ignore_index=True)\n",
    "                row_all = pd.DataFrame({\"Mass\": [EM], \"Standoff distance\": [SD], \"Angle\": [A], \"Arrival time\": [AT], \"Change time\": [CT], \"Trough time\": [TT], \"End time\": [ET]})\n",
    "                df_all = pd.concat([df_all, row_all], ignore_index=True)\n",
    "                \n",
    "                # Create a dictionary with the arrays\n",
    "                data1 = {'Time': time,\n",
    "                        'Smoothed_Pressure': smoothed_pressure,\n",
    "                        'Pressure': pressure}\n",
    "                data2 = {'Adj Time': time[peak_index: zero_crossing_index_2+1],\n",
    "                        'Adj Pressure': smoothed_pressure[peak_index: zero_crossing_index_2+1]}\n",
    "                \n",
    "                # Create DataFrames from dictionaries\n",
    "                df1 = pd.DataFrame(data1)\n",
    "                df2 = pd.DataFrame(data2)\n",
    "                \n",
    "                # Concatenate DataFrames along the columns\n",
    "                df_combined = pd.concat([df1, df2], axis=1)\n",
    "                \n",
    "                # Create a DataFrame from the dictionary\n",
    "                df3 = pd.DataFrame(df_combined)\n",
    "                \n",
    "                # Write dataframe in excel template\n",
    "                wb.sheets[0].range(\"A1\").options(index=False).value = df3\n",
    "                \n",
    "                print (\"file_name\",file_name)\n",
    "                \n",
    "                # Create files in output directory\n",
    "                wb.save(output_dir1/f\"{file_name}.xlsx\") \n",
    "                \n",
    "            else:\n",
    "                print(\"Less than two peaks found in the data.\")\n",
    "                \n",
    "                # Create a dictionary with the arrays\n",
    "                data3 = {'Time': time,'Pressure': pressure}\n",
    "                \n",
    "                # Create a DataFrame from the dictionary\n",
    "                df4 = pd.DataFrame(data3)\n",
    "                \n",
    "                # Write dataframe in excel template\n",
    "                wb.sheets[0].range(\"A1\").options(index=False).value = df4\n",
    "                \n",
    "                print (\"file_name\",file_name)\n",
    "                \n",
    "                # Create files in output directory\n",
    "                wb.save(output_dir1/f\"{file_name}.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2fef1fe985792e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
